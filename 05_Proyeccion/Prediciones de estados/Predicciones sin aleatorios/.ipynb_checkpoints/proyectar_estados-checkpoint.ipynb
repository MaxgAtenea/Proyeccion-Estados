{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#Typing\n",
    "from typing import List\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57188f68-e8e2-484f-9922-26322269fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75a0c7",
   "metadata": {},
   "source": [
    "### **Notebook para proyectar los estados de las convocatorias de J√≥venes a la U**\n",
    "\n",
    "**Estructura**:\n",
    "1.  Lectura de datos y del Pipeline (Fine tuned)\n",
    "2.  Definicion de las matrices de aprobaci√≥n y perdida acumulada\n",
    "3.  Limpieza del dataframe\n",
    "4.  Definicion de funciones para la predicci√≥n.\n",
    "5.  Ejecuci√≥n de las predicciones.\n",
    "6.  TO DO: Limpieza de casos atipicos\n",
    "7.  Graficas con los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb029415-2000-4e34-a92b-8b1c745a00a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha actual: 20251028\n"
     ]
    }
   ],
   "source": [
    "fecha_actual = datetime.now().strftime(\"%Y%m%d\")\n",
    "print(f\"Fecha actual: {fecha_actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b424b",
   "metadata": {},
   "source": [
    "### **Lectura de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4b5635-3004-4fed-ab16-8d11ee575eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Panel: V12\n"
     ]
    }
   ],
   "source": [
    "WEIGHTS_PATH = \"../../../03_Modeling/Classification_Task/05_Fine_Tuning/pesos_modelo/\"\n",
    "DATA_PATH = \"../../../03_Modeling/Classification_Task/99_Data/Future_Engineering/\"\n",
    "\n",
    "data_file = \"panel_after_futureengineering_panelV12.pkl\"\n",
    "version_panel = re.search(r'V\\d{2}', data_file).group(0)\n",
    "print(f\"Version Panel: {version_panel}\")\n",
    "\n",
    "df = pd.read_pickle(DATA_PATH + data_file) #panel_estudiantes_v2509.pkl\n",
    "\n",
    "pipeline = joblib.load(WEIGHTS_PATH + \"pipeline_rf_panelV12.pkl\")\n",
    "le = joblib.load(WEIGHTS_PATH + \"labelencoder_panelV12.pkl\")\n",
    "thresholds_pr = joblib.load(WEIGHTS_PATH + \"prob_thresholds_precisionRecall_panelV12.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8d3b74-1ef8-4753-bace-61af53ad9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def documentos_no_crecientes(df: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Devuelve una lista de documentos cuyo campo 'periodo_orden'\n",
    "    no es estrictamente creciente dentro de cada grupo de 'DOCUMENTO'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con las columnas 'DOCUMENTO' y 'periodo_orden'.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: Lista de identificadores de documentos no crecientes.\n",
    "    \"\"\"\n",
    "    group = df.groupby(\"DOCUMENTO\")['periodo_orden']\n",
    "    return [doc for doc, periodo in group if not periodo.is_monotonic_increasing]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3090dcd2-96b5-4584-ae6e-8a37ca1141aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos donde periodo_orden no est√° en orden cronol√≥gico []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Documentos donde periodo_orden no est√° en orden cronol√≥gico {documentos_no_crecientes(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be943247-7582-461a-ba88-2b7f12bae421",
   "metadata": {},
   "source": [
    "**Corecci√≥n de duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37cf6b60-42f2-4b62-a1e7-7b5520b0e50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observaciones antes de correci√≥n de duplicados: 132060\n",
      "Observaciones despu√©s de correci√≥n de duplicados: 132060\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observaciones antes de correci√≥n de duplicados: {df.shape[0]}\")\n",
    "df = df.drop_duplicates(subset=[\"DOCUMENTO\", \"estado\", \"periodo_key\"], keep=\"first\")\n",
    "print(f\"Observaciones despu√©s de correci√≥n de duplicados: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5556271-771a-42d6-b42b-75fe218ae2c4",
   "metadata": {},
   "source": [
    "**Convocatorias a predecir**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf64463",
   "metadata": {},
   "source": [
    "### **Definir matrices de aprobaci√≥n y perdida acumulada por semestre**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc5744-a2cb-4334-896d-2c973ab1f50d",
   "metadata": {},
   "source": [
    "### **Matrices de aprobaci√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13b06a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distr_apr_tecnico = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.90, 1.00],\n",
    "    3:  [0.39, 0.74, 1.00],\n",
    "    4:  [0.32, 0.61, 0.82, 1.00],\n",
    "    5:  [0.28, 0.53, 0.71, 0.86, 1.00],\n",
    "    6:  [0.25, 0.47, 0.63, 0.76, 0.89, 1.00],\n",
    "    7:  [0.22, 0.42, 0.57, 0.69, 0.80, 0.90, 1.00],\n",
    "    8:  [0.20, 0.38, 0.52, 0.63, 0.73, 0.82, 0.91, 1.00],\n",
    "    9:  [0.19, 0.35, 0.48, 0.58, 0.67, 0.76, 0.84, 0.92, 1.00],\n",
    "    10: [0.17, 0.33, 0.44, 0.54, 0.63, 0.71, 0.79, 0.86, 0.93, 1.00],\n",
    "    11: [0.16, 0.31, 0.42, 0.51, 0.59, 0.66, 0.74, 0.80, 0.87, 0.94, 1.00],\n",
    "    12: [0.15, 0.29, 0.39, 0.48, 0.55, 0.62, 0.69, 0.76, 0.82, 0.88, 0.94, 1.00]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "Distr_apr_tecnologico = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.41, 1.00],\n",
    "    3:  [0.28, 0.69, 1.00],\n",
    "    4:  [0.22, 0.54, 0.79, 1.00],\n",
    "    5:  [0.19, 0.46, 0.66, 0.84, 1.00],\n",
    "    6:  [0.16, 0.40, 0.57, 0.73, 0.87, 1.00],\n",
    "    7:  [0.14, 0.35, 0.51, 0.65, 0.77, 0.89, 1.00],\n",
    "    8:  [0.13, 0.32, 0.46, 0.58, 0.69, 0.80, 0.90, 1.00],\n",
    "    9:  [0.12, 0.29, 0.42, 0.53, 0.63, 0.73, 0.82, 0.91, 1.00],\n",
    "    10: [0.11, 0.27, 0.39, 0.49, 0.58, 0.67, 0.76, 0.84, 0.92, 1.00],\n",
    "    11: [0.10, 0.25, 0.36, 0.45, 0.54, 0.62, 0.70, 0.78, 0.86, 0.93, 1.00],\n",
    "    12: [0.09, 0.23, 0.33, 0.42, 0.51, 0.58, 0.66, 0.73, 0.80, 0.87, 0.93, 1.00],\n",
    "    13: [0.09, 0.22, 0.31, 0.40, 0.48, 0.55, 0.62, 0.68, 0.75, 0.81, 0.88, 0.94, 1.00],\n",
    "    14: [0.08, 0.20, 0.30, 0.38, 0.45, 0.52, 0.58, 0.65, 0.71, 0.77, 0.83, 0.89, 0.94, 1.00],\n",
    "    15: [0.08, 0.19, 0.28, 0.36, 0.42, 0.49, 0.55, 0.61, 0.67, 0.73, 0.78, 0.84, 0.89, 0.95, 1.00],\n",
    "    16: [0.07, 0.18, 0.27, 0.34, 0.40, 0.46, 0.52, 0.58, 0.64, 0.69, 0.74, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "Distr_apr_universitario = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.45, 1.00],\n",
    "    3:  [0.29, 0.64, 1.00],\n",
    "    4:  [0.22, 0.49, 0.77, 1.00],\n",
    "    5:  [0.18, 0.40, 0.63, 0.83, 1.00],\n",
    "    6:  [0.16, 0.35, 0.54, 0.71, 0.861, 1.00],\n",
    "    7:  [0.14, 0.31, 0.48, 0.63, 0.76, 0.88, 1.00],\n",
    "    8:  [0.12, 0.28, 0.43, 0.57, 0.69, 0.80, 0.90, 1.00],\n",
    "    9:  [0.11, 0.25, 0.39, 0.52, 0.62, 0.73, 0.82, 0.91, 1.00],\n",
    "    10: [0.10, 0.23, 0.36, 0.48, 0.58, 0.67, 0.76, 0.84, 0.92, 1.00],\n",
    "    11: [0.10, 0.21, 0.34, 0.44, 0.53, 0.62, 0.70, 0.78, 0.86, 0.93, 1.00],\n",
    "    12: [0.09, 0.20, 0.32, 0.41, 0.50, 0.58, 0.66, 0.73, 0.80, 0.87, 0.93, 1.00],\n",
    "    13: [0.08, 0.19, 0.30, 0.39, 0.47, 0.54, 0.62, 0.68, 0.75, 0.81, 0.88, 0.94, 1.00],\n",
    "    14: [0.08, 0.18, 0.28, 0.37, 0.44, 0.51, 0.58, 0.65, 0.71, 0.77, 0.83, 0.89, 0.94, 1.00],\n",
    "    15: [0.08, 0.17, 0.26, 0.35, 0.42, 0.49, 0.55, 0.61, 0.67, 0.73, 0.78, 0.84, 0.89, 0.95, 1.00],\n",
    "    16: [0.07, 0.16, 0.25, 0.33, 0.40, 0.46, 0.52, 0.58, 0.64, 0.69, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00],\n",
    "    17: [0.07, 0.15, 0.24, 0.31, 0.38, 0.44, 0.50, 0.55, 0.61, 0.66, 0.71, 0.76, 0.81, 0.86, 0.91, 0.95, 1.00],\n",
    "    18: [0.07, 0.15, 0.23, 0.30, 0.36, 0.42, 0.48, 0.53, 0.58, 0.63, 0.68, 0.73, 0.77, 0.82, 0.87, 0.91, 0.96, 1.00]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4f335-cc69-410f-9a0a-9a1e8a5bac3d",
   "metadata": {},
   "source": [
    "### **Matrices de p√©rdida**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3117287a-3e98-4910-b9b6-4d55e7c53d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Matrices de perdida acumulada\n",
    "\n",
    "Distr_tecnico = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.90, 1.00],\n",
    "    3:  [0.75, 0.91, 1.00],\n",
    "    4:  [0.70, 0.85, 0.94, 1.00],\n",
    "    5:  [0.67, 0.81, 0.90, 0.95, 1.00],\n",
    "    6:  [0.65, 0.78, 0.86, 0.92, 0.96, 1.00],\n",
    "    7:  [0.63, 0.76, 0.84, 0.89, 0.94, 0.97, 1.00],\n",
    "    8:  [0.61, 0.74, 0.82, 0.87, 0.91, 0.95, 0.98, 1.00],\n",
    "    9:  [0.60, 0.73, 0.80, 0.85, 0.89, 0.93, 0.95, 0.98, 1.00],\n",
    "    10: [0.59, 0.71, 0.79, 0.84, 0.88, 0.91, 0.94, 0.96, 0.98, 1.00],\n",
    "    11: [0.58, 0.70, 0.77, 0.82, 0.86, 0.89, 0.92, 0.94, 0.96, 0.98, 1.00],\n",
    "    12: [0.57, 0.69, 0.76, 0.81, 0.85, 0.88, 0.91, 0.93, 0.95, 0.97, 0.98, 1.00]\n",
    "}\n",
    "\n",
    "Distr_tecnologico = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.46, 1.00],\n",
    "    3:  [0.35, 0.76, 1.00],\n",
    "    4:  [0.30, 0.65, 0.86, 1.00],\n",
    "    5:  [0.27, 0.59, 0.77, 0.90, 1.00],\n",
    "    6:  [0.25, 0.54, 0.71, 0.83, 0.92, 1.00],\n",
    "    7:  [0.24, 0.51, 0.67, 0.78, 0.87, 0.94, 1.00],\n",
    "    8:  [0.22, 0.48, 0.63, 0.74, 0.82, 0.89, 0.95, 1.00],\n",
    "    9:  [0.21, 0.46, 0.61, 0.71, 0.79, 0.86, 0.91, 0.96, 1.00],\n",
    "    10: [0.21, 0.45, 0.59, 0.68, 0.76, 0.82, 0.88, 0.92, 0.96, 1.00],\n",
    "    11: [0.20, 0.43, 0.57, 0.66, 0.74, 0.80, 0.85, 0.89, 0.93, 0.97, 1.00],\n",
    "    12: [0.19, 0.42, 0.55, 0.64, 0.72, 0.78, 0.83, 0.87, 0.91, 0.94, 0.97, 1.00],\n",
    "    13: [0.19, 0.41, 0.54, 0.63, 0.70, 0.76, 0.80, 0.85, 0.88, 0.92, 0.95, 0.97, 1.00],\n",
    "    14: [0.19, 0.40, 0.52, 0.61, 0.68, 0.74, 0.79, 0.83, 0.86, 0.90, 0.93, 0.95, 0.98, 1.00],\n",
    "    15: [0.18, 0.39, 0.51, 0.60, 0.67, 0.72, 0.77, 0.81, 0.85, 0.88, 0.91, 0.93, 0.96, 0.98, 1.00],\n",
    "    16: [0.18, 0.38, 0.50, 0.59, 0.66, 0.71, 0.75, 0.79, 0.83, 0.86, 0.89, 0.91, 0.94, 0.96, 0.98, 1.00]\n",
    "}\n",
    "\n",
    "Distr_universitario = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.67, 1.00],\n",
    "    3:  [0.56, 0.84, 1.00],\n",
    "    4:  [0.50, 0.75, 0.90, 1.00],\n",
    "    5:  [0.46, 0.69, 0.83, 0.93, 1.00],\n",
    "    6:  [0.44, 0.65, 0.78, 0.87, 0.943, 1.00],\n",
    "    7:  [0.42, 0.62, 0.75, 0.83, 0.90, 0.95, 1.00],\n",
    "    8:  [0.40, 0.60, 0.72, 0.80, 0.86, 0.92, 0.96, 1.00],\n",
    "    9:  [0.39, 0.58, 0.69, 0.77, 0.84, 0.89, 0.93, 0.97, 1.00],\n",
    "    10: [0.38, 0.56, 0.67, 0.75, 0.81, 0.86, 0.90, 0.94, 0.97, 1.00],\n",
    "    11: [0.37, 0.55, 0.66, 0.73, 0.79, 0.84, 0.88, 0.92, 0.95, 0.97, 1.00],\n",
    "    12: [0.36, 0.54, 0.64, 0.72, 0.77, 0.82, 0.86, 0.90, 0.93, 0.95, 0.98, 1.00],\n",
    "    13: [0.35, 0.53, 0.63, 0.70, 0.76, 0.80, 0.84, 0.88, 0.91, 0.93, 0.96, 0.98, 1.00],\n",
    "    14: [0.35, 0.52, 0.62, 0.69, 0.74, 0.79, 0.83, 0.86, 0.89, 0.92, 0.94, 0.96, 0.98, 1.00],\n",
    "    15: [0.34, 0.51, 0.61, 0.68, 0.73, 0.78, 0.81, 0.85, 0.88, 0.90, 0.92, 0.95, 0.97, 0.98, 1.00],\n",
    "    16: [0.33, 0.50, 0.60, 0.67, 0.72, 0.76, 0.80, 0.83, 0.86, 0.89, 0.91, 0.93, 0.95, 0.97, 0.98, 1.00],\n",
    "    17: [0.33, 0.49, 0.59, 0.66, 0.71, 0.75, 0.79, 0.82, 0.85, 0.87, 0.90, 0.92, 0.94, 0.95, 0.97, 0.99, 1.00],\n",
    "    18: [0.32, 0.49, 0.58, 0.65, 0.70, 0.74, 0.78, 0.81, 0.84, 0.86, 0.88, 0.91, 0.92, 0.94, 0.96, 0.97, 0.99, 1.00]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153049a",
   "metadata": {},
   "source": [
    "**Manipulaci√≥n dataframe**\n",
    "1. Normalizar periodos a semestres\n",
    "2. Recuperar la √∫ltima observaci√≥n de los jovenes de JE1 y JE2\n",
    "3. Obtener los datos de JU1-JU6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295d649-3f95-4888-8fc2-34fd845b54cc",
   "metadata": {},
   "source": [
    "**1. Normalizar periodos a semestres**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61f223-f135-4468-8360-b25a032094aa",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "\n",
    "- [ ] La normalizaci√≥n de los periodos debe ir en la secci√≥n de cleaning o future engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19173128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PERIODOS_BD_SNIES\"] = np.where(\n",
    "    (df[\"PERIODOS_BD_SNIES\"] > 12) &\n",
    "    (df[\"NIVEL_FORMACION\"] != \"UNIVERSITARIO\"),\n",
    "    df[\"PERIODOS_BD_SNIES\"] // 6,  # conversi√≥n a semestres\n",
    "    df[\"PERIODOS_BD_SNIES\"]        # se mantiene igual\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed21cc0-38ea-417e-a015-1afc540728fe",
   "metadata": {},
   "source": [
    "**2. Recuperar la ultima observacion de los Jovenes de JE1 y JE2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7d789b5-1ce3-41f9-b330-dc260b2b5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuperar la ultima observaciones de los jovenes de JE1 y JE2.\n",
    "\n",
    "# Filtramos por convocatoria\n",
    "df_JE = df.query(\"CONVOCATORIA in ['JE1', 'JE2']\")\n",
    "\n",
    "# Si 'semestre' indica el orden temporal, usamos sort_values + drop_duplicates\n",
    "#dataframe con los jovenes de JE1 y JE2\n",
    "df_ultimas_observaciones_je = (\n",
    "    df_JE\n",
    "    .sort_values([\"DOCUMENTO\", \"semestre\"], ascending = True)   # ordenamos por documento y semestre\n",
    "    .drop_duplicates(\"DOCUMENTO\", keep=\"last\") # nos quedamos con la √∫ltima por documento\n",
    ")\n",
    "\n",
    "df_ultimas_observaciones_je[\n",
    "    'creditos_x_semestre'\n",
    "    ] = df_ultimas_observaciones_je['CREDITOS_PROGRAMA']/df_ultimas_observaciones_je['PERIODOS_BD_SNIES']\n",
    "\n",
    "df_ultimas_observaciones_je['pct_aprob_acum_teorica'] = (\n",
    "    df_ultimas_observaciones_je.creditos_x_semestre/df_ultimas_observaciones_je.CREDITOS_PROGRAMA\n",
    ")*df_ultimas_observaciones_je['semestre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d161c8f6-b560-47e4-84eb-9e82eaa41f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CONVOCATORIA\n",
       "JE1    2296\n",
       "JE2      34\n",
       "Name: DOCUMENTO, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_JE.groupby(\"CONVOCATORIA\")[\"DOCUMENTO\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e053674a-367c-4f82-badb-ed40c2d89e68",
   "metadata": {},
   "source": [
    "**3. Obtener los datos de JU1-JU6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3a6a365-1c37-4d7a-8509-02e0ae9ded14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JU = df[~df[\"DOCUMENTO\"].isin(df_ultimas_observaciones_je[\"DOCUMENTO\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f7ace-171d-4207-972d-b87a23b280c9",
   "metadata": {},
   "source": [
    "## **Pipeline de predicci√≥n**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8a1ed",
   "metadata": {},
   "source": [
    "**Definicion de funciones para la predicci√≥n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cb24302-ea47-4aa6-b956-f361321adfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_thresholds(\n",
    "    pipeline: \"sklearn.pipeline.Pipeline\",\n",
    "    X: \"pd.DataFrame | np.ndarray\",\n",
    "    thresholds: dict[str, float],\n",
    "    classes: \"list[str] | np.ndarray\"\n",
    ") -> tuple[list[str], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Genera predicciones aplicando umbrales personalizados por clase en lugar de \n",
    "    usar el criterio est√°ndar de argmax de predict_proba. Tambi√©n devuelve las\n",
    "    probabilidades estimadas por el modelo para cada clase.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pipeline : sklearn.Pipeline\n",
    "        Pipeline ya entrenado que incluye tanto el preprocesamiento como el modelo.\n",
    "    X : pandas.DataFrame o numpy.ndarray\n",
    "        Observaciones de entrada para predecir.\n",
    "    thresholds : dict[str, float]\n",
    "        Diccionario con thresholds por clase, e.g. {\"Abandono\": 0.5, \"Aplazado\": 0.42, \"Matriculado\": 0.5}.\n",
    "    classes : list[str] o np.ndarray\n",
    "        Lista de clases en el mismo orden que las columnas de predict_proba (e.g. le.classes_).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    preds : list[str]\n",
    "        Lista de etiquetas predichas (una por observaci√≥n).\n",
    "    probas_df : pandas.DataFrame\n",
    "        DataFrame con las probabilidades por clase. \n",
    "        Las columnas se nombran como \"prob_<nombre_clase>\".\n",
    "        Ejemplo: [\"prob_Abandono\", \"prob_Aplazado\", \"prob_Matriculado\"].\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Para cada observaci√≥n, se identifican las clases cuya probabilidad supera su threshold.\n",
    "    - Si varias clases lo superan, se elige la de mayor probabilidad.\n",
    "    - Si ninguna supera su threshold, se usa el argmax tradicional.\n",
    "    - Esta versi√≥n extiende la anterior agregando las probabilidades por clase al retorno.\n",
    "    \"\"\"\n",
    "    probas = pipeline.predict_proba(X)\n",
    "    preds = []\n",
    "\n",
    "    # recorrer cada observaci√≥n\n",
    "    for row in probas:\n",
    "        passed = [c for c, p in zip(classes, row) if p >= thresholds[c]]\n",
    "        if passed:\n",
    "            idx = np.argmax([row[list(classes).index(c)] for c in passed])\n",
    "            final_class = passed[idx]\n",
    "        else:\n",
    "            final_class = classes[row.argmax()]\n",
    "        preds.append(final_class)\n",
    "\n",
    "    # convertir probabilidades a DataFrame con nombres de columnas claros\n",
    "    probas_df = pd.DataFrame(probas, columns=[f\"prob_{c}\" for c in classes])\n",
    "\n",
    "    return preds, probas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa450c2f-dede-4058-82da-473efef2c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Estados absorbentes\n",
    "# ==========================\n",
    "ABSORBENTES = {\"Graduado\", \"Abandono\", \"P√©rdida_del_beneficio\", \"Sin_bolsa_de_creditos\"}\n",
    "\n",
    "# ==========================\n",
    "# Funci√≥n de predicci√≥n (reglas + modelo)\n",
    "# ==========================\n",
    "def predecir_estado(\n",
    "    df: pd.DataFrame,\n",
    "    pipeline: \"sklearn.pipeline.Pipeline\",\n",
    "    le: \"sklearn.preprocessing.LabelEncoder\",\n",
    "    thresholds: dict[str, float]\n",
    ") -> dict[str, list]:\n",
    "    \"\"\"\n",
    "    Predice el estado siguiente aplicando primero reglas de negocio y,\n",
    "    si no se cumplen, usa el modelo con thresholds optimizados.\n",
    "\n",
    "    Si una observaci√≥n cumple una regla, se asigna una probabilidad de 1.0 \n",
    "    a la clase correspondiente y se registra la raz√≥n textual.\n",
    "    Si no cumple ninguna regla, el estado y las probabilidades se obtienen \n",
    "    del modelo predictivo.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame de entrada con las variables necesarias para la predicci√≥n.\n",
    "    pipeline : sklearn.Pipeline\n",
    "        Pipeline entrenado (incluye preprocesamiento y modelo).\n",
    "    le : sklearn.preprocessing.LabelEncoder\n",
    "        Codificador de etiquetas de clase (usado para mapear las salidas del modelo).\n",
    "    thresholds : dict[str, float]\n",
    "        Umbrales personalizados por clase (e.g. {\"Abandono\": 0.5, \"Aplazado\": 0.42, \"Matriculado\": 0.5}).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resultados : dict\n",
    "        Diccionario con tres llaves:\n",
    "        - \"estado\": list[str] ‚Üí etiqueta final por observaci√≥n.\n",
    "        - \"probabilidades\": list[dict[str, float]] ‚Üí probabilidades por clase.\n",
    "        - \"razon_estado\": list[str] ‚Üí descripci√≥n textual del origen:\n",
    "            - \"Regla: ...\" si se aplic√≥ una regla.\n",
    "            - \"Modelo\" si fue predicho por el modelo.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Las reglas de negocio tienen prioridad sobre las predicciones del modelo.\n",
    "    - Las probabilidades del modelo provienen de `pipeline.predict_proba(X)` y se ajustan\n",
    "      seg√∫n los thresholds especificados.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    n = len(df)\n",
    "\n",
    "    # Inicializaci√≥n de vectores\n",
    "    resultados = np.full(n, None, dtype=object)\n",
    "    razon_estado = np.full(n, None, dtype=object)\n",
    "    probas_df = pd.DataFrame(0.0, index=df.index, columns=[f\"prob_{c}\" for c in le.classes_])\n",
    "\n",
    "    # ====== REGLAS vectorizadas ======\n",
    "    reglas = [\n",
    "        (df[\"N_Aplazado\"] >= 4, \"Abandono\", \"Regla: 4 o m√°s aplazados consecutivos\"),\n",
    "        (df[\"N_Abandono\"] >= 1, \"Abandono\", \"Regla: Historial de abandono previo\"),\n",
    "        (df[\"N_Sin_bolsa_de_creditos\"] >= 1, \"Sin_bolsa_de_creditos\", \"Regla: Ya tuvo sin bolsa de cr√©ditos\"),\n",
    "        (\n",
    "            (df[\"pct_aprob_acum\"] + df[\"pct_perd_acum\"] >= 1.1)\n",
    "            & (df[\"N_Periodos_adicionales\"] < 4)\n",
    "            & (df[\"pct_perd_acum\"] > 0.1),\n",
    "            \"Sin_bolsa_de_creditos\",\n",
    "            \"Regla: Exceso de cr√©ditos acumulados (>110%) con p√©rdida moderada\"\n",
    "        ),\n",
    "        (df[\"N_Periodos_adicionales\"] > 4, \"P√©rdida_del_beneficio\", \"Regla: M√°s de 4 periodos adicionales\"),\n",
    "        (df[\"N_P√©rdida_del_beneficio\"] >= 1, \"P√©rdida_del_beneficio\", \"Regla: Ya tuvo p√©rdida del beneficio\"),\n",
    "        (df[\"N_Graduado\"] >= 1, \"Graduado\", \"Regla: Ya tiene graduado\"),\n",
    "        (df[\"pct_aprob_acum\"] >= 0.95, \"Graduado\", \"Regla: Aprob√≥ 95% o m√°s de los cr√©ditos\"),\n",
    "    ]\n",
    "\n",
    "    # Aplicar reglas\n",
    "    for mask, estado, razon in reglas:\n",
    "        resultados[mask.values] = estado\n",
    "        razon_estado[mask.values] = razon\n",
    "        clase_col = f\"prob_{estado}\"\n",
    "        if clase_col in probas_df.columns:\n",
    "            probas_df.loc[mask, clase_col] = 1.0  # Regla = probabilidad total 1\n",
    "\n",
    "    # ====== MODELO ======\n",
    "    mask_modelo = pd.isna(resultados)\n",
    "    if mask_modelo.any():\n",
    "        # Obtener predicciones y probabilidades del modelo\n",
    "        X_pred = df.loc[mask_modelo, :]\n",
    "        y_proba = pipeline.predict_proba(X_pred)\n",
    "\n",
    "        # Convertir a DataFrame\n",
    "        model_probas = pd.DataFrame(y_proba, columns=[f\"prob_{c}\" for c in le.classes_], index=X_pred.index)\n",
    "        probas_df.loc[mask_modelo, :] = model_probas\n",
    "\n",
    "        # Aplicar thresholds personalizados\n",
    "        for i, row in model_probas.iterrows():\n",
    "            clase_pred = None\n",
    "            for clase in le.classes_:\n",
    "                if clase not in thresholds:\n",
    "                    raise ValueError(f\"No se encontr√≥ threshold definido para la clase '{clase}'\")\n",
    "                if row[f\"prob_{clase}\"] >= thresholds[clase]:\n",
    "                    clase_pred = clase\n",
    "                    break\n",
    "            # Asignar la predicci√≥n: primera clase que cumple threshold o argmax\n",
    "            resultados[i] = clase_pred if clase_pred else le.classes_[np.argmax(row.values)]\n",
    "            razon_estado[i] = \"Modelo\"\n",
    "\n",
    "\n",
    "    # ====== RESULTADO FINAL ======\n",
    "    # Convertimos las filas de probas_df en dicts para devolver una estructura m√°s limpia\n",
    "    probabilidades = [\n",
    "        {col.replace(\"prob_\", \"\"): row[col] for col in probas_df.columns}\n",
    "        for _, row in probas_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"estado\": resultados.tolist(),\n",
    "        \"probabilidades\": probabilidades,\n",
    "        \"razon_estado\": razon_estado.tolist(),\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Funci√≥n auxiliar para actualizar % acumulados\n",
    "# ==========================\n",
    "def actualizar_pct(\n",
    "    pct_actual: float,\n",
    "    periodo: int,\n",
    "    distr: dict[int, list[float]]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Actualiza el porcentaje acumulado de aprobaci√≥n o p√©rdida \n",
    "    del periodo t ‚Üí t+1 usando una distribuci√≥n emp√≠rica.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pct_actual : float\n",
    "        Porcentaje acumulado actual del estudiante (entre 0 y 1).\n",
    "    periodo : int\n",
    "        N√∫mero de periodo o semestre actual del estudiante.\n",
    "    distr : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de porcentajes para el nivel de formaci√≥n,\n",
    "        donde las claves son los periodos y los valores son listas de porcentajes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Porcentaje acumulado actualizado, truncado a un m√°ximo de 1.0.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Si la distribuci√≥n no contiene informaci√≥n suficiente (lista vac√≠a o con menos de 2 elementos),\n",
    "      el porcentaje acumulado no se modifica.\n",
    "    - Si el valor pen√∫ltimo de la lista es cero, se evita la divisi√≥n y se conserva el valor actual.\n",
    "    - El valor resultante se limita a 1.0 como m√°ximo.\n",
    "    \"\"\"\n",
    "\n",
    "    lista_t1 = distr.get(periodo)\n",
    "    if not lista_t1 or len(lista_t1) < 2:\n",
    "        return pct_actual\n",
    "    penultimo = lista_t1[-2]\n",
    "    if penultimo == 0:\n",
    "        return pct_actual\n",
    "    nuevo_pct = pct_actual / penultimo\n",
    "    return min(nuevo_pct, 1.0)\n",
    "\n",
    "# ==========================\n",
    "# Simulaci√≥n de trayectoria\n",
    "# ==========================\n",
    "def simular_trayectoria(\n",
    "    fila_inicial: pd.Series,\n",
    "    clf: \"sklearn.pipeline.Pipeline\",\n",
    "    le: \"sklearn.preprocessing.LabelEncoder\",\n",
    "    Distr_apr_tecnico: dict[int, list[float]],\n",
    "    Distr_tecnico: dict[int, list[float]],\n",
    "    Distr_apr_tecnologico: dict[int, list[float]],\n",
    "    Distr_tecnologico: dict[int, list[float]],\n",
    "    Distr_apr_universitario: dict[int, list[float]],\n",
    "    Distr_universitario: dict[int, list[float]],\n",
    "    thresholds: dict[str, float],\n",
    "    max_iter: int = 20\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simula la trayectoria acad√©mica de un estudiante a lo largo de varios semestres,\n",
    "    aplicando reglas de negocio y predicciones de un modelo supervisado.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fila_inicial : pandas.Series\n",
    "        Registro inicial del estudiante con sus variables acad√©micas y de contexto.\n",
    "        Debe incluir campos como \"NIVEL_FORMACION\", \"semestre\", \"pct_aprob_acum\", etc.\n",
    "    clf : sklearn.Pipeline\n",
    "        Pipeline entrenado que contiene el preprocesamiento y el modelo predictivo.\n",
    "    le : sklearn.preprocessing.LabelEncoder\n",
    "        Codificador de etiquetas usado durante el entrenamiento del modelo.\n",
    "    Distr_apr_tecnico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos aprobados por semestre (nivel t√©cnico).\n",
    "    Distr_tecnico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos perdidos por semestre (nivel t√©cnico).\n",
    "    Distr_apr_tecnologico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos aprobados por semestre (nivel tecnol√≥gico).\n",
    "    Distr_tecnologico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos perdidos por semestre (nivel tecnol√≥gico).\n",
    "    Distr_apr_universitario : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos aprobados por semestre (nivel universitario).\n",
    "    Distr_universitario : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos perdidos por semestre (nivel universitario).\n",
    "    thresholds : dict[str, float]\n",
    "        Umbrales por clase usados para ajustar las predicciones del modelo.\n",
    "    max_iter : int, optional (default=20)\n",
    "        N√∫mero m√°ximo de semestres a simular.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Trayectoria completa del estudiante, donde cada fila representa\n",
    "        un semestre simulado con sus variables actualizadas y el estado\n",
    "        resultante (\"Matriculado\", \"Abandono\", \"Graduado\", etc.).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - La simulaci√≥n avanza semestre a semestre hasta alcanzar un estado absorbente\n",
    "      (por ejemplo, \"Abandono\" o \"Graduado\") o el l√≠mite de iteraciones.\n",
    "    - Se actualizan din√°micamente los contadores de estado, los porcentajes acumulados\n",
    "      y los periodos adicionales con base en reglas emp√≠ricas y las predicciones del modelo.\n",
    "    - Por defecto, todo estudiante inicia en estado \"Matriculado\" si no se especifica otro.\n",
    "    \"\"\"\n",
    "\n",
    "    fila = fila_inicial.to_dict()\n",
    "    nivel = fila[\"NIVEL_FORMACION\"]\n",
    "\n",
    "    if \"TECNICA\" in nivel.upper():\n",
    "        distr_aprob, distr_perd = Distr_apr_tecnico, Distr_tecnico\n",
    "    elif \"TECNOLOG\" in nivel.upper():\n",
    "        distr_aprob, distr_perd = Distr_apr_tecnologico, Distr_tecnologico\n",
    "    elif \"UNIVERSITARIO\" in nivel.upper():\n",
    "        distr_aprob, distr_perd = Distr_apr_universitario, Distr_universitario\n",
    "    else:\n",
    "        raise ValueError(f\"Nivel de formaci√≥n no reconocido: {nivel}\")\n",
    "\n",
    "    # ====== estado inicial ======\n",
    "    #Esto garantiza que toda simulaci√≥n arranque con un estado definido, y por defecto se asume que todo estudiante parte como \"Matriculado\".\n",
    "    fila[\"estado\"] = fila.get(\"estado\", \"Matriculado\")\n",
    "    \n",
    "    # üîπ CAMBIO 1: ahora predecir_estado devuelve tambi√©n probabilidades y raz√≥n\n",
    "    pred_estado = predecir_estado(pd.DataFrame([fila]), clf, le, thresholds)\n",
    "\n",
    "    # Extraer valores de la tupla devuelta (estado, dict_probs, razon)\n",
    "    fila[\"estado_next\"] = pred_estado[\"estado\"][0]\n",
    "    fila[\"razon_estado\"] = pred_estado[\"razon_estado\"][0]\n",
    "    \n",
    "    # Crear columnas de probabilidad por clase (prob_<clase>)\n",
    "    for clase, prob in pred_estado[\"probabilidades\"][0].items():\n",
    "        fila[f\"prob_{clase}\"] = prob\n",
    "    \n",
    "    trayectoria = [fila.copy()]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        if fila[\"estado\"] in ABSORBENTES:\n",
    "            break\n",
    "        estado_actual = fila[\"estado_next\"]\n",
    "        \n",
    "        nueva = fila.copy()\n",
    "        nueva[\"estado\"] = estado_actual\n",
    "        nueva[\"semestre\"] += 1\n",
    "\n",
    "        # ====== contadores ======\n",
    "        key = f\"N_{estado_actual}\"\n",
    "        if key in nueva:\n",
    "            nueva[key] += 1\n",
    "\n",
    "        # ====== actualizar % ======\n",
    "        if estado_actual == \"Matriculado\":\n",
    "            periodo = int(nueva[\"N_Matriculado\"])\n",
    "            if (periodo + 1) not in distr_aprob or (periodo + 1) not in distr_perd:\n",
    "                break\n",
    "            nueva[\"pct_aprob_acum\"] = actualizar_pct(fila[\"pct_aprob_acum\"], periodo, distr_aprob)\n",
    "            nueva[\"pct_perd_acum\"] = actualizar_pct(fila[\"pct_perd_acum\"], periodo, distr_perd)\n",
    "\n",
    "        # ====== periodos adicionales ======\n",
    "        nueva[\"N_Periodos_adicionales\"] = max(nueva[\"semestre\"] - nueva[\"PERIODOS_BD_SNIES\"], 0)\n",
    "        nueva[\"N_Matriculas_adicionales\"] = max(nueva[\"N_Matriculado\"] - nueva[\"PERIODOS_BD_SNIES\"], 0)\n",
    "\n",
    "        # ====== periodo_key ======\n",
    "        pk = fila[\"periodo_key\"]\n",
    "        anio, sem = divmod(pk, 10)\n",
    "        nueva[\"periodo_key\"] = anio * 10 + (2 if sem == 1 else 1 + 10)\n",
    "\n",
    "        # ====== estado siguiente ======\n",
    "        # üîπ CAMBIO 2: incluir tambi√©n probabilidades y raz√≥n del estado\n",
    "        pred_estado = predecir_estado(pd.DataFrame([nueva]), clf, le, thresholds)\n",
    "        \n",
    "        nueva[\"estado_next\"] = pred_estado[\"estado\"][0]\n",
    "        nueva[\"razon_estado\"] = pred_estado[\"razon_estado\"][0]\n",
    "        \n",
    "        # Crear columnas de probabilidad por clase (prob_<clase>)\n",
    "        for clase, prob in pred_estado[\"probabilidades\"][0].items():\n",
    "            nueva[f\"prob_{clase}\"] = prob\n",
    "        \n",
    "\n",
    "        trayectoria.append(nueva.copy())\n",
    "        fila = nueva\n",
    "\n",
    "        if nueva[\"estado_next\"] in ABSORBENTES:\n",
    "            final = fila.copy()\n",
    "            final[\"estado\"] = final[\"estado_next\"]\n",
    "            key = f\"N_{final['estado_next']}\"\n",
    "            if key in final:\n",
    "                final[key] += 1\n",
    "            trayectoria.append(final.copy())\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(trayectoria)\n",
    "\n",
    "# ==========================\n",
    "# Simular todas las c√©dulas\n",
    "# ==========================\n",
    "def simular_todas(\n",
    "    df: pd.DataFrame,\n",
    "    clf: \"sklearn.pipeline.Pipeline\",\n",
    "    le: \"sklearn.preprocessing.LabelEncoder\",\n",
    "    Distr_apr_tecnico: dict[int, list[float]],\n",
    "    Distr_tecnico: dict[int, list[float]],\n",
    "    Distr_apr_tecnologico: dict[int, list[float]],\n",
    "    Distr_tecnologico: dict[int, list[float]],\n",
    "    Distr_apr_universitario: dict[int, list[float]],\n",
    "    Distr_universitario: dict[int, list[float]],\n",
    "    thresholds: dict[str, float],\n",
    "    max_iter: int = 20\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simula las trayectorias acad√©micas de todos los estudiantes √∫nicos en un DataFrame,\n",
    "    llamando internamente a `simular_trayectoria` para cada c√©dula.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataset filtrado con la informaci√≥n inicial de los estudiantes.\n",
    "        Puede contener m√∫ltiples filas por c√©dula, pero se tomar√° la √∫ltima.\n",
    "    pipeline : sklearn.Pipeline\n",
    "        Pipeline entrenado que incluye preprocesamiento y modelo predictivo.\n",
    "    le : sklearn.preprocessing.LabelEncoder\n",
    "        Codificador de clases utilizado durante el entrenamiento del modelo.\n",
    "    Distr_apr_tecnico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos aprobados por semestre (nivel t√©cnico).\n",
    "    Distr_tecnico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos perdidos por semestre (nivel t√©cnico).\n",
    "    Distr_apr_tecnologico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos aprobados por semestre (nivel tecnol√≥gico).\n",
    "    Distr_tecnologico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos perdidos por semestre (nivel tecnol√≥gico).\n",
    "    Distr_apr_universitario : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos aprobados por semestre (nivel universitario).\n",
    "    Distr_universitario : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos perdidos por semestre (nivel universitario).\n",
    "    thresholds : dict[str, float]\n",
    "        Diccionario con los umbrales personalizados por clase.\n",
    "    max_iter : int, optional (default=20)\n",
    "        N√∫mero m√°ximo de semestres a simular por estudiante.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame consolidado con las trayectorias de todos los estudiantes.\n",
    "        Cada c√©dula aparece repetida a lo largo de su secuencia temporal simulada.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - La funci√≥n identifica los estudiantes √∫nicos por el campo \"DOCUMENTO\".\n",
    "    - Se toma una √∫nica fila inicial por c√©dula (la m√°s reciente).\n",
    "    - Cada estudiante se simula de manera independiente mediante `simular_trayectoria`.\n",
    "    - Los resultados se concatenan en un √∫nico DataFrame final.\n",
    "    \"\"\"\n",
    "\n",
    "    df_iniciales = df.drop_duplicates(subset=[\"DOCUMENTO\"], keep = 'last').set_index(\"DOCUMENTO\")\n",
    "\n",
    "    trayectorias = []\n",
    "\n",
    "    for cedula, fila in df_iniciales.iterrows():\n",
    "        trayectoria = simular_trayectoria(\n",
    "            fila, pipeline, le,\n",
    "            Distr_apr_tecnico, Distr_tecnico,\n",
    "            Distr_apr_tecnologico, Distr_tecnologico,\n",
    "            Distr_apr_universitario, Distr_universitario,\n",
    "            thresholds, max_iter\n",
    "        )\n",
    "        trayectoria[\"CEDULA\"] = cedula\n",
    "        trayectorias.append(trayectoria)\n",
    "\n",
    "    return pd.concat(trayectorias, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43b1c564-166a-414e-af62-1a10c98397b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simular_todas_paralelo(\n",
    "    df: pd.DataFrame,\n",
    "    pipeline: \"sklearn.pipeline.Pipeline\",\n",
    "    le: \"sklearn.preprocessing.LabelEncoder\",\n",
    "    Distr_apr_tecnico: dict[int, list[float]],\n",
    "    Distr_tecnico: dict[int, list[float]],\n",
    "    Distr_apr_tecnologico: dict[int, list[float]],\n",
    "    Distr_tecnologico: dict[int, list[float]],\n",
    "    Distr_apr_universitario: dict[int, list[float]],\n",
    "    Distr_universitario: dict[int, list[float]],\n",
    "    thresholds: dict[str, float],\n",
    "    max_iter: int = 20,\n",
    "    n_jobs: int = -1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simula trayectorias acad√©micas para todas las c√©dulas en paralelo usando joblib,\n",
    "    mostrando una barra de progreso mediante tqdm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataset original con estudiantes (puede contener m√∫ltiples filas por c√©dula).\n",
    "        Se tomar√° una √∫nica fila por estudiante (la m√°s reciente).\n",
    "    pipeline : sklearn.Pipeline\n",
    "        Pipeline entrenado que incluye tanto el preprocesamiento como el modelo predictivo.\n",
    "    le : sklearn.preprocessing.LabelEncoder\n",
    "        Codificador de clases usado en el entrenamiento.\n",
    "    Distr_apr_tecnico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos aprobados por semestre (nivel t√©cnico).\n",
    "    Distr_tecnico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos perdidos por semestre (nivel t√©cnico).\n",
    "    Distr_apr_tecnologico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos aprobados por semestre (nivel tecnol√≥gico).\n",
    "    Distr_tecnologico : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos perdidos por semestre (nivel tecnol√≥gico).\n",
    "    Distr_apr_universitario : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos aprobados por semestre (nivel universitario).\n",
    "    Distr_universitario : dict[int, list[float]]\n",
    "        Distribuci√≥n emp√≠rica de cr√©ditos perdidos por semestre (nivel universitario).\n",
    "    thresholds : dict[str, float]\n",
    "        Diccionario con umbrales personalizados por clase.\n",
    "    max_iter : int, optional (default=20)\n",
    "        N√∫mero m√°ximo de semestres a simular por estudiante.\n",
    "    n_jobs : int, optional (default=-1)\n",
    "        N√∫mero de n√∫cleos a utilizar en paralelo (-1 = usar todos los disponibles).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame concatenado con las trayectorias simuladas de todos los estudiantes.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Utiliza `joblib.Parallel` y `joblib.delayed` para acelerar la simulaci√≥n.\n",
    "    - Muestra una barra de progreso mediante `tqdm` durante la ejecuci√≥n.\n",
    "    - Internamente llama a `simular_trayectoria` para cada c√©dula.\n",
    "    - Cada fila del DataFrame resultante representa un estado temporal en la trayectoria simulada.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 0. MUY IMPORTANTE: Orden cronologicamente las observaciones. \n",
    "    df = df.sort_values(by=[\"DOCUMENTO\", \"semestre\"], ascending=True) \n",
    "    # 1. MUY IMPORTANTE: Tomar la observaci√≥n m√°s reciente del individuo.\n",
    "    df_iniciales = df.drop_duplicates(subset=[\"DOCUMENTO\"], keep = 'last').set_index(\"DOCUMENTO\")\n",
    "\n",
    "    # 2. Definir funci√≥n para cada c√©dula\n",
    "    def simular_por_cedula(fila):\n",
    "        trayectoria = simular_trayectoria(\n",
    "            fila_inicial=fila,\n",
    "            clf=pipeline,\n",
    "            le=le,\n",
    "            Distr_apr_tecnico=Distr_apr_tecnico,\n",
    "            Distr_tecnico=Distr_tecnico,\n",
    "            Distr_apr_tecnologico=Distr_apr_tecnologico,\n",
    "            Distr_tecnologico=Distr_tecnologico,\n",
    "            Distr_apr_universitario=Distr_apr_universitario,\n",
    "            Distr_universitario=Distr_universitario,\n",
    "            thresholds=thresholds,\n",
    "            max_iter=max_iter\n",
    "        )\n",
    "        trayectoria[\"CEDULA\"] = fila.name\n",
    "        return trayectoria\n",
    "\n",
    "    # 3. Paralelizar ejecuci√≥n con tqdm sobre iterrows\n",
    "    trayectorias = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(simular_por_cedula)(fila)\n",
    "        for _, fila in tqdm(df_iniciales.iterrows(),\n",
    "                            total=len(df_iniciales),\n",
    "                            desc=\"Simulando trayectorias\")\n",
    "    )\n",
    "\n",
    "    # 4. Concatenar resultados\n",
    "    return pd.concat(trayectorias, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd225c0-7b7c-4f51-801f-477620fd2db4",
   "metadata": {},
   "source": [
    "**Escenarios de proyeccion para JE1 Y JE2:**\n",
    "\n",
    "0. Asumir que todos el mundo tendr√° m√≠nimo el 10% de aprobacion\n",
    "1. Asumir que todo el mundo tendr√° el % de aprobaci√≥n teorica\n",
    "2. Asumir que el % de aprobaci√≥n se comportar√° como el % de aprobaci√≥n teorica m√°s un ruido gaussiano\n",
    "3. Asumir que el % de aprobaci√≥n se comportar√° como se ha comportado en los primeros 2 semestres del pasado\n",
    "\n",
    "En este punto tenemos:\n",
    "- **a)** Dataframe con todos los jovenes (aka *df*)\n",
    "- **b)** dataframe con las observaciones de JE1 y JE2  (aka df_ultimas_observaciones_je)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36671b48-aa4b-4665-a927-ea7ec9686efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escenario 2: Asumir que todos los que tienen pct aprobado == 0 aprobaran el 10% + o - un ruido Gaussiano\n",
    "# Fijamos la semilla\n",
    "np.random.seed(42)\n",
    "\n",
    "mask = df_ultimas_observaciones_je['pct_aprob_acum'] == 0\n",
    "\n",
    "# Generamos ruido gaussiano reproducible SOLO para los ceros\n",
    "ruido = np.random.normal(loc=0.03, scale=0.01, size=mask.sum())\n",
    "\n",
    "df_ultimas_observaciones_je.loc[mask, 'pct_aprob_acum'] = 0.1 + ruido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264b605-406d-439f-adbf-2d68c0ca514f",
   "metadata": {},
   "source": [
    "**Seleccion del DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1464204-4aaf-4c41-929c-ce27bfff7adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0d8ec7993943ac829b084f38af442a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Selecciona df:', layout=Layout(width='60%'), options=(('JE', 'JE'), ('JU', 'JU'), ('Comp‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Diccionario con las tres opciones de dataframes---\n",
    "dataframes = {\n",
    "    \"JE\": df_ultimas_observaciones_je,\n",
    "    \"JU\": df_JU,\n",
    "    \"completo\": df\n",
    "}\n",
    "\n",
    "# --- Instanciar selector interactivo ---\n",
    "selector_df = widgets.Dropdown(\n",
    "    options=[(\"JE\", \"JE\"),\n",
    "             (\"JU\", \"JU\"),\n",
    "             (\"Completo JU-JE\", \"completo\"),\n",
    "            ],\n",
    "    description=\"Selecciona df:\",\n",
    "    value=\"JE\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"60%\")\n",
    ")\n",
    "\n",
    "display(selector_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994e824-74e8-473b-a75c-88dcb5b64d0a",
   "metadata": {},
   "source": [
    "**Simular las trayectorias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05ec4d48-d263-43f9-8b2e-bc0907fcd83a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulando trayectorias: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2330/2330 [12:28<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "df_trayectorias = simular_todas_paralelo(\n",
    "    df=dataframes[selector_df.value], #Posibles dataframes: df_ultimas_observaciones_je,#df,\n",
    "    pipeline=pipeline,\n",
    "    le=le,\n",
    "    Distr_apr_tecnico=Distr_apr_tecnico,\n",
    "    Distr_tecnico=Distr_tecnico,\n",
    "    Distr_apr_tecnologico=Distr_apr_tecnologico,\n",
    "    Distr_tecnologico=Distr_tecnologico,\n",
    "    Distr_apr_universitario=Distr_apr_universitario,\n",
    "    Distr_universitario=Distr_universitario,\n",
    "    thresholds=thresholds_pr,\n",
    "    max_iter=20,\n",
    "    n_jobs=-1  # Usa todos los n√∫cleos disponibles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855adba",
   "metadata": {},
   "source": [
    "**Guardar resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d59dcb68-33dd-43b4-a5ac-91b2815c74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trayectorias.to_pickle(f\"trayectorias/trayectorias_{selector_df.value}_panel{version_panel}_{fecha_actual}.pkl\")\n",
    "df_trayectorias.to_excel(f\"trayectorias/trayectorias_{selector_df.value}_panel{version_panel}_{fecha_actual}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821e9f5-257b-4680-8b67-ae618b9bafdc",
   "metadata": {},
   "source": [
    "**Nota: 16-10-2025**\n",
    "\n",
    "Dado que el modelo est√° sobreestimando los abandonos para JE1 y JE2, vamos a utilizar el modelo de abandono hecho por Ra√∫l. \n",
    "El flujo (provicional) es pasarle la base de las personas tales que:\n",
    "\n",
    "1. Su estado actual no es abandono pero su estado_next lo es.\n",
    "2. El modelo clasific√≥ al beneficiario en abanadono directamente (no se explica por otra regla)\n",
    "\n",
    "**Nota**\n",
    "- El modelo de Ra√∫l clasifica abandonos para los primeros 3 semestres, lo cual es ideal para este ejercicio, toda vez que las sobreestimaciones se est√°n dando en los primeros 3 periodos.\n",
    "\n",
    "**Reflexiones**\n",
    "- Si bien el recall de Ra√∫l es muy bueno (~~80%) la precisi√≥n es baja (~20%), lo cual implica que la sobreestimaci√≥n seguir√° ocurriendo (muchos falsos positivos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca11fbca-21bd-4131-90e0-f3934d1971c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trayectorias.query(\n",
    "    \"(estado_next == 'Abandono') & (razon_estado == 'Modelo') & (estado!='Abandono')\"\n",
    ")[['CEDULA', 'CONVOCATORIA']].to_excel(f\"abandono/clasificados_como_abandono_{selector_df.value}_{fecha_actual}.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
