{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae76c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import joblib\n",
    "import re\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "#Typing\n",
    "from typing import List\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57188f68-e8e2-484f-9922-26322269fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a75a0c7",
   "metadata": {},
   "source": [
    "### **Notebook para proyectar los estados de las convocatorias de Jóvenes a la U**\n",
    "\n",
    "**Estructura**:\n",
    "1.  Lectura de datos y del Pipeline (Fine tuned)\n",
    "2.  Definicion de las matrices de aprobación y perdida acumulada\n",
    "3.  Limpieza del dataframe\n",
    "4.  Definicion de funciones para la predicción.\n",
    "5.  Ejecución de las predicciones.\n",
    "6.  TO DO: Limpieza de casos atipicos\n",
    "7.  Graficas con los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb029415-2000-4e34-a92b-8b1c745a00a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha actual: 20251028\n"
     ]
    }
   ],
   "source": [
    "fecha_actual = datetime.now().strftime(\"%Y%m%d\")\n",
    "print(f\"Fecha actual: {fecha_actual}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79b424b",
   "metadata": {},
   "source": [
    "### **Lectura de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4b5635-3004-4fed-ab16-8d11ee575eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version Panel: V12\n"
     ]
    }
   ],
   "source": [
    "WEIGHTS_PATH = \"../../../03_Modeling/Classification_Task/05_Fine_Tuning/pesos_modelo/\"\n",
    "DATA_PATH = \"../../../03_Modeling/Classification_Task/99_Data/Future_Engineering/\"\n",
    "\n",
    "data_file = \"panel_after_futureengineering_panelV12.pkl\"\n",
    "version_panel = re.search(r'V\\d{2}', data_file).group(0)\n",
    "print(f\"Version Panel: {version_panel}\")\n",
    "\n",
    "df = pd.read_pickle(DATA_PATH + data_file) #panel_estudiantes_v2509.pkl\n",
    "\n",
    "pipeline = joblib.load(WEIGHTS_PATH + \"pipeline_rf_panelV12.pkl\")\n",
    "le = joblib.load(WEIGHTS_PATH + \"labelencoder_panelV12.pkl\")\n",
    "thresholds_pr = joblib.load(WEIGHTS_PATH + \"prob_thresholds_precisionRecall_panelV12.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8d3b74-1ef8-4753-bace-61af53ad9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def documentos_no_crecientes(df: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Devuelve una lista de documentos cuyo campo 'periodo_orden'\n",
    "    no es estrictamente creciente dentro de cada grupo de 'DOCUMENTO'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con las columnas 'DOCUMENTO' y 'periodo_orden'.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: Lista de identificadores de documentos no crecientes.\n",
    "    \"\"\"\n",
    "    group = df.groupby(\"DOCUMENTO\")['periodo_orden']\n",
    "    return [doc for doc, periodo in group if not periodo.is_monotonic_increasing]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3090dcd2-96b5-4584-ae6e-8a37ca1141aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos donde periodo_orden no está en orden cronológico []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Documentos donde periodo_orden no está en orden cronológico {documentos_no_crecientes(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be943247-7582-461a-ba88-2b7f12bae421",
   "metadata": {},
   "source": [
    "**Corección de duplicados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37cf6b60-42f2-4b62-a1e7-7b5520b0e50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observaciones antes de correción de duplicados: 132060\n",
      "Observaciones después de correción de duplicados: 132060\n"
     ]
    }
   ],
   "source": [
    "print(f\"Observaciones antes de correción de duplicados: {df.shape[0]}\")\n",
    "df = df.drop_duplicates(subset=[\"DOCUMENTO\", \"estado\", \"periodo_key\"], keep=\"first\")\n",
    "print(f\"Observaciones después de correción de duplicados: {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5556271-771a-42d6-b42b-75fe218ae2c4",
   "metadata": {},
   "source": [
    "**Convocatorias a predecir**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf64463",
   "metadata": {},
   "source": [
    "### **Definir matrices de aprobación y perdida acumulada por semestre**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc5744-a2cb-4334-896d-2c973ab1f50d",
   "metadata": {},
   "source": [
    "### **Matrices de aprobación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13b06a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distr_apr_tecnico = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.90, 1.00],\n",
    "    3:  [0.39, 0.74, 1.00],\n",
    "    4:  [0.32, 0.61, 0.82, 1.00],\n",
    "    5:  [0.28, 0.53, 0.71, 0.86, 1.00],\n",
    "    6:  [0.25, 0.47, 0.63, 0.76, 0.89, 1.00],\n",
    "    7:  [0.22, 0.42, 0.57, 0.69, 0.80, 0.90, 1.00],\n",
    "    8:  [0.20, 0.38, 0.52, 0.63, 0.73, 0.82, 0.91, 1.00],\n",
    "    9:  [0.19, 0.35, 0.48, 0.58, 0.67, 0.76, 0.84, 0.92, 1.00],\n",
    "    10: [0.17, 0.33, 0.44, 0.54, 0.63, 0.71, 0.79, 0.86, 0.93, 1.00],\n",
    "    11: [0.16, 0.31, 0.42, 0.51, 0.59, 0.66, 0.74, 0.80, 0.87, 0.94, 1.00],\n",
    "    12: [0.15, 0.29, 0.39, 0.48, 0.55, 0.62, 0.69, 0.76, 0.82, 0.88, 0.94, 1.00]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "Distr_apr_tecnologico = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.41, 1.00],\n",
    "    3:  [0.28, 0.69, 1.00],\n",
    "    4:  [0.22, 0.54, 0.79, 1.00],\n",
    "    5:  [0.19, 0.46, 0.66, 0.84, 1.00],\n",
    "    6:  [0.16, 0.40, 0.57, 0.73, 0.87, 1.00],\n",
    "    7:  [0.14, 0.35, 0.51, 0.65, 0.77, 0.89, 1.00],\n",
    "    8:  [0.13, 0.32, 0.46, 0.58, 0.69, 0.80, 0.90, 1.00],\n",
    "    9:  [0.12, 0.29, 0.42, 0.53, 0.63, 0.73, 0.82, 0.91, 1.00],\n",
    "    10: [0.11, 0.27, 0.39, 0.49, 0.58, 0.67, 0.76, 0.84, 0.92, 1.00],\n",
    "    11: [0.10, 0.25, 0.36, 0.45, 0.54, 0.62, 0.70, 0.78, 0.86, 0.93, 1.00],\n",
    "    12: [0.09, 0.23, 0.33, 0.42, 0.51, 0.58, 0.66, 0.73, 0.80, 0.87, 0.93, 1.00],\n",
    "    13: [0.09, 0.22, 0.31, 0.40, 0.48, 0.55, 0.62, 0.68, 0.75, 0.81, 0.88, 0.94, 1.00],\n",
    "    14: [0.08, 0.20, 0.30, 0.38, 0.45, 0.52, 0.58, 0.65, 0.71, 0.77, 0.83, 0.89, 0.94, 1.00],\n",
    "    15: [0.08, 0.19, 0.28, 0.36, 0.42, 0.49, 0.55, 0.61, 0.67, 0.73, 0.78, 0.84, 0.89, 0.95, 1.00],\n",
    "    16: [0.07, 0.18, 0.27, 0.34, 0.40, 0.46, 0.52, 0.58, 0.64, 0.69, 0.74, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "Distr_apr_universitario = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.45, 1.00],\n",
    "    3:  [0.29, 0.64, 1.00],\n",
    "    4:  [0.22, 0.49, 0.77, 1.00],\n",
    "    5:  [0.18, 0.40, 0.63, 0.83, 1.00],\n",
    "    6:  [0.16, 0.35, 0.54, 0.71, 0.861, 1.00],\n",
    "    7:  [0.14, 0.31, 0.48, 0.63, 0.76, 0.88, 1.00],\n",
    "    8:  [0.12, 0.28, 0.43, 0.57, 0.69, 0.80, 0.90, 1.00],\n",
    "    9:  [0.11, 0.25, 0.39, 0.52, 0.62, 0.73, 0.82, 0.91, 1.00],\n",
    "    10: [0.10, 0.23, 0.36, 0.48, 0.58, 0.67, 0.76, 0.84, 0.92, 1.00],\n",
    "    11: [0.10, 0.21, 0.34, 0.44, 0.53, 0.62, 0.70, 0.78, 0.86, 0.93, 1.00],\n",
    "    12: [0.09, 0.20, 0.32, 0.41, 0.50, 0.58, 0.66, 0.73, 0.80, 0.87, 0.93, 1.00],\n",
    "    13: [0.08, 0.19, 0.30, 0.39, 0.47, 0.54, 0.62, 0.68, 0.75, 0.81, 0.88, 0.94, 1.00],\n",
    "    14: [0.08, 0.18, 0.28, 0.37, 0.44, 0.51, 0.58, 0.65, 0.71, 0.77, 0.83, 0.89, 0.94, 1.00],\n",
    "    15: [0.08, 0.17, 0.26, 0.35, 0.42, 0.49, 0.55, 0.61, 0.67, 0.73, 0.78, 0.84, 0.89, 0.95, 1.00],\n",
    "    16: [0.07, 0.16, 0.25, 0.33, 0.40, 0.46, 0.52, 0.58, 0.64, 0.69, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00],\n",
    "    17: [0.07, 0.15, 0.24, 0.31, 0.38, 0.44, 0.50, 0.55, 0.61, 0.66, 0.71, 0.76, 0.81, 0.86, 0.91, 0.95, 1.00],\n",
    "    18: [0.07, 0.15, 0.23, 0.30, 0.36, 0.42, 0.48, 0.53, 0.58, 0.63, 0.68, 0.73, 0.77, 0.82, 0.87, 0.91, 0.96, 1.00]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab4f335-cc69-410f-9a0a-9a1e8a5bac3d",
   "metadata": {},
   "source": [
    "### **Matrices de pérdida**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3117287a-3e98-4910-b9b6-4d55e7c53d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Matrices de perdida acumulada\n",
    "\n",
    "Distr_tecnico = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.90, 1.00],\n",
    "    3:  [0.75, 0.91, 1.00],\n",
    "    4:  [0.70, 0.85, 0.94, 1.00],\n",
    "    5:  [0.67, 0.81, 0.90, 0.95, 1.00],\n",
    "    6:  [0.65, 0.78, 0.86, 0.92, 0.96, 1.00],\n",
    "    7:  [0.63, 0.76, 0.84, 0.89, 0.94, 0.97, 1.00],\n",
    "    8:  [0.61, 0.74, 0.82, 0.87, 0.91, 0.95, 0.98, 1.00],\n",
    "    9:  [0.60, 0.73, 0.80, 0.85, 0.89, 0.93, 0.95, 0.98, 1.00],\n",
    "    10: [0.59, 0.71, 0.79, 0.84, 0.88, 0.91, 0.94, 0.96, 0.98, 1.00],\n",
    "    11: [0.58, 0.70, 0.77, 0.82, 0.86, 0.89, 0.92, 0.94, 0.96, 0.98, 1.00],\n",
    "    12: [0.57, 0.69, 0.76, 0.81, 0.85, 0.88, 0.91, 0.93, 0.95, 0.97, 0.98, 1.00]\n",
    "}\n",
    "\n",
    "Distr_tecnologico = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.46, 1.00],\n",
    "    3:  [0.35, 0.76, 1.00],\n",
    "    4:  [0.30, 0.65, 0.86, 1.00],\n",
    "    5:  [0.27, 0.59, 0.77, 0.90, 1.00],\n",
    "    6:  [0.25, 0.54, 0.71, 0.83, 0.92, 1.00],\n",
    "    7:  [0.24, 0.51, 0.67, 0.78, 0.87, 0.94, 1.00],\n",
    "    8:  [0.22, 0.48, 0.63, 0.74, 0.82, 0.89, 0.95, 1.00],\n",
    "    9:  [0.21, 0.46, 0.61, 0.71, 0.79, 0.86, 0.91, 0.96, 1.00],\n",
    "    10: [0.21, 0.45, 0.59, 0.68, 0.76, 0.82, 0.88, 0.92, 0.96, 1.00],\n",
    "    11: [0.20, 0.43, 0.57, 0.66, 0.74, 0.80, 0.85, 0.89, 0.93, 0.97, 1.00],\n",
    "    12: [0.19, 0.42, 0.55, 0.64, 0.72, 0.78, 0.83, 0.87, 0.91, 0.94, 0.97, 1.00],\n",
    "    13: [0.19, 0.41, 0.54, 0.63, 0.70, 0.76, 0.80, 0.85, 0.88, 0.92, 0.95, 0.97, 1.00],\n",
    "    14: [0.19, 0.40, 0.52, 0.61, 0.68, 0.74, 0.79, 0.83, 0.86, 0.90, 0.93, 0.95, 0.98, 1.00],\n",
    "    15: [0.18, 0.39, 0.51, 0.60, 0.67, 0.72, 0.77, 0.81, 0.85, 0.88, 0.91, 0.93, 0.96, 0.98, 1.00],\n",
    "    16: [0.18, 0.38, 0.50, 0.59, 0.66, 0.71, 0.75, 0.79, 0.83, 0.86, 0.89, 0.91, 0.94, 0.96, 0.98, 1.00]\n",
    "}\n",
    "\n",
    "Distr_universitario = {\n",
    "    1:  [1.00],\n",
    "    2:  [0.67, 1.00],\n",
    "    3:  [0.56, 0.84, 1.00],\n",
    "    4:  [0.50, 0.75, 0.90, 1.00],\n",
    "    5:  [0.46, 0.69, 0.83, 0.93, 1.00],\n",
    "    6:  [0.44, 0.65, 0.78, 0.87, 0.943, 1.00],\n",
    "    7:  [0.42, 0.62, 0.75, 0.83, 0.90, 0.95, 1.00],\n",
    "    8:  [0.40, 0.60, 0.72, 0.80, 0.86, 0.92, 0.96, 1.00],\n",
    "    9:  [0.39, 0.58, 0.69, 0.77, 0.84, 0.89, 0.93, 0.97, 1.00],\n",
    "    10: [0.38, 0.56, 0.67, 0.75, 0.81, 0.86, 0.90, 0.94, 0.97, 1.00],\n",
    "    11: [0.37, 0.55, 0.66, 0.73, 0.79, 0.84, 0.88, 0.92, 0.95, 0.97, 1.00],\n",
    "    12: [0.36, 0.54, 0.64, 0.72, 0.77, 0.82, 0.86, 0.90, 0.93, 0.95, 0.98, 1.00],\n",
    "    13: [0.35, 0.53, 0.63, 0.70, 0.76, 0.80, 0.84, 0.88, 0.91, 0.93, 0.96, 0.98, 1.00],\n",
    "    14: [0.35, 0.52, 0.62, 0.69, 0.74, 0.79, 0.83, 0.86, 0.89, 0.92, 0.94, 0.96, 0.98, 1.00],\n",
    "    15: [0.34, 0.51, 0.61, 0.68, 0.73, 0.78, 0.81, 0.85, 0.88, 0.90, 0.92, 0.95, 0.97, 0.98, 1.00],\n",
    "    16: [0.33, 0.50, 0.60, 0.67, 0.72, 0.76, 0.80, 0.83, 0.86, 0.89, 0.91, 0.93, 0.95, 0.97, 0.98, 1.00],\n",
    "    17: [0.33, 0.49, 0.59, 0.66, 0.71, 0.75, 0.79, 0.82, 0.85, 0.87, 0.90, 0.92, 0.94, 0.95, 0.97, 0.99, 1.00],\n",
    "    18: [0.32, 0.49, 0.58, 0.65, 0.70, 0.74, 0.78, 0.81, 0.84, 0.86, 0.88, 0.91, 0.92, 0.94, 0.96, 0.97, 0.99, 1.00]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6153049a",
   "metadata": {},
   "source": [
    "**Manipulación dataframe**\n",
    "1. Normalizar periodos a semestres\n",
    "2. Recuperar la última observación de los jovenes de JE1 y JE2\n",
    "3. Obtener los datos de JU1-JU6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5295d649-3f95-4888-8fc2-34fd845b54cc",
   "metadata": {},
   "source": [
    "**1. Normalizar periodos a semestres**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d61f223-f135-4468-8360-b25a032094aa",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "\n",
    "- [ ] La normalización de los periodos debe ir en la sección de cleaning o future engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19173128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"PERIODOS_BD_SNIES\"] = np.where(\n",
    "    (df[\"PERIODOS_BD_SNIES\"] > 12) &\n",
    "    (df[\"NIVEL_FORMACION\"] != \"UNIVERSITARIO\"),\n",
    "    df[\"PERIODOS_BD_SNIES\"] // 6,  # conversión a semestres\n",
    "    df[\"PERIODOS_BD_SNIES\"]        # se mantiene igual\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed21cc0-38ea-417e-a015-1afc540728fe",
   "metadata": {},
   "source": [
    "**2. Recuperar la ultima observacion de los Jovenes de JE1 y JE2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7d789b5-1ce3-41f9-b330-dc260b2b5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuperar la ultima observaciones de los jovenes de JE1 y JE2.\n",
    "\n",
    "# Filtramos por convocatoria\n",
    "df_JE = df.query(\"CONVOCATORIA in ['JE1', 'JE2']\")\n",
    "\n",
    "# Si 'semestre' indica el orden temporal, usamos sort_values + drop_duplicates\n",
    "#dataframe con los jovenes de JE1 y JE2\n",
    "df_ultimas_observaciones_je = (\n",
    "    df_JE\n",
    "    .sort_values([\"DOCUMENTO\", \"semestre\"], ascending = True)   # ordenamos por documento y semestre\n",
    "    .drop_duplicates(\"DOCUMENTO\", keep=\"last\") # nos quedamos con la última por documento\n",
    ")\n",
    "\n",
    "df_ultimas_observaciones_je[\n",
    "    'creditos_x_semestre'\n",
    "    ] = df_ultimas_observaciones_je['CREDITOS_PROGRAMA']/df_ultimas_observaciones_je['PERIODOS_BD_SNIES']\n",
    "\n",
    "df_ultimas_observaciones_je['pct_aprob_acum_teorica'] = (\n",
    "    df_ultimas_observaciones_je.creditos_x_semestre/df_ultimas_observaciones_je.CREDITOS_PROGRAMA\n",
    ")*df_ultimas_observaciones_je['semestre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d161c8f6-b560-47e4-84eb-9e82eaa41f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CONVOCATORIA\n",
       "JE1    2296\n",
       "JE2      34\n",
       "Name: DOCUMENTO, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_JE.groupby(\"CONVOCATORIA\")[\"DOCUMENTO\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e053674a-367c-4f82-badb-ed40c2d89e68",
   "metadata": {},
   "source": [
    "**3. Obtener los datos de JU1-JU6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3a6a365-1c37-4d7a-8509-02e0ae9ded14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JU = df[~df[\"DOCUMENTO\"].isin(df_ultimas_observaciones_je[\"DOCUMENTO\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f7ace-171d-4207-972d-b87a23b280c9",
   "metadata": {},
   "source": [
    "## **Pipeline de predicción**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd8a1ed",
   "metadata": {},
   "source": [
    "**Definicion de funciones para la predicción**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cb24302-ea47-4aa6-b956-f361321adfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_thresholds(\n",
    "    pipeline: \"sklearn.pipeline.Pipeline\",\n",
    "    X: \"pd.DataFrame | np.ndarray\",\n",
    "    thresholds: dict[str, float],\n",
    "    classes: \"list[str] | np.ndarray\"\n",
    ") -> tuple[list[str], pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Genera predicciones aplicando umbrales personalizados por clase en lugar de \n",
    "    usar el criterio estándar de argmax de predict_proba. También devuelve las\n",
    "    probabilidades estimadas por el modelo para cada clase.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pipeline : sklearn.Pipeline\n",
    "        Pipeline ya entrenado que incluye tanto el preprocesamiento como el modelo.\n",
    "    X : pandas.DataFrame o numpy.ndarray\n",
    "        Observaciones de entrada para predecir.\n",
    "    thresholds : dict[str, float]\n",
    "        Diccionario con thresholds por clase, e.g. {\"Abandono\": 0.5, \"Aplazado\": 0.42, \"Matriculado\": 0.5}.\n",
    "    classes : list[str] o np.ndarray\n",
    "        Lista de clases en el mismo orden que las columnas de predict_proba (e.g. le.classes_).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    preds : list[str]\n",
    "        Lista de etiquetas predichas (una por observación).\n",
    "    probas_df : pandas.DataFrame\n",
    "        DataFrame con las probabilidades por clase. \n",
    "        Las columnas se nombran como \"prob_<nombre_clase>\".\n",
    "        Ejemplo: [\"prob_Abandono\", \"prob_Aplazado\", \"prob_Matriculado\"].\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Para cada observación, se identifican las clases cuya probabilidad supera su threshold.\n",
    "    - Si varias clases lo superan, se elige la de mayor probabilidad.\n",
    "    - Si ninguna supera su threshold, se usa el argmax tradicional.\n",
    "    - Esta versión extiende la anterior agregando las probabilidades por clase al retorno.\n",
    "    \"\"\"\n",
    "    probas = pipeline.predict_proba(X)\n",
    "    preds = []\n",
    "\n",
    "    # recorrer cada observación\n",
    "    for row in probas:\n",
    "        passed = [c for c, p in zip(classes, row) if p >= thresholds[c]]\n",
    "        if passed:\n",
    "            idx = np.argmax([row[list(classes).index(c)] for c in passed])\n",
    "            final_class = passed[idx]\n",
    "        else:\n",
    "            final_class = classes[row.argmax()]\n",
    "        preds.append(final_class)\n",
    "\n",
    "    # convertir probabilidades a DataFrame con nombres de columnas claros\n",
    "    probas_df = pd.DataFrame(probas, columns=[f\"prob_{c}\" for c in classes])\n",
    "\n",
    "    return preds, probas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa450c2f-dede-4058-82da-473efef2c9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================\n",
    "# Estados absorbentes\n",
    "# ==========================\n",
    "ABSORBENTES = {\"Graduado\", \"Abandono\", \"Pérdida_del_beneficio\", \"Sin_bolsa_de_creditos\"}\n",
    "\n",
    "# ==========================\n",
    "# Función de predicción (reglas + modelo)\n",
    "# ==========================\n",
    "def predecir_estado(\n",
    "    df: pd.DataFrame,\n",
    "    pipeline: \"sklearn.pipeline.Pipeline\",\n",
    "    le: \"sklearn.preprocessing.LabelEncoder\",\n",
    "    thresholds: dict[str, float]\n",
    ") -> dict[str, list]:\n",
    "    \"\"\"\n",
    "    Predice el estado siguiente aplicando primero reglas de negocio y,\n",
    "    si no se cumplen, usa el modelo con thresholds optimizados.\n",
    "\n",
    "    Si una observación cumple una regla, se asigna una probabilidad de 1.0 \n",
    "    a la clase correspondiente y se registra la razón textual.\n",
    "    Si no cumple ninguna regla, el estado y las probabilidades se obtienen \n",
    "    del modelo predictivo.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame de entrada con las variables necesarias para la predicción.\n",
    "    pipeline : sklearn.Pipeline\n",
    "        Pipeline entrenado (incluye preprocesamiento y modelo).\n",
    "    le : sklearn.preprocessing.LabelEncoder\n",
    "        Codificador de etiquetas de clase (usado para mapear las salidas del modelo).\n",
    "    thresholds : dict[str, float]\n",
    "        Umbrales personalizados por clase (e.g. {\"Abandono\": 0.5, \"Aplazado\": 0.42, \"Matriculado\": 0.5}).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resultados : dict\n",
    "        Diccionario con tres llaves:\n",
    "        - \"estado\": list[str] → etiqueta final por observación.\n",
    "        - \"probabilidades\": list[dict[str, float]] → probabilidades por clase.\n",
    "        - \"razon_estado\": list[str] → descripción textual del origen:\n",
    "            - \"Regla: ...\" si se aplicó una regla.\n",
    "            - \"Modelo\" si fue predicho por el modelo.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Las reglas de negocio tienen prioridad sobre las predicciones del modelo.\n",
    "    - Las probabilidades del modelo provienen de `pipeline.predict_proba(X)` y se ajustan\n",
    "      según los thresholds especificados.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    n = len(df)\n",
    "\n",
    "    # Inicialización de vectores\n",
    "    resultados = np.full(n, None, dtype=object)\n",
    "    razon_estado = np.full(n, None, dtype=object)\n",
    "    probas_df = pd.DataFrame(0.0, index=df.index, columns=[f\"prob_{c}\" for c in le.classes_])\n",
    "\n",
    "    # ====== REGLAS vectorizadas ======\n",
    "    reglas = [\n",
    "        (df[\"N_Aplazado\"] >= 4, \"Abandono\", \"Regla: 4 o más aplazados consecutivos\"),\n",
    "        (df[\"N_Abandono\"] >= 1, \"Abandono\", \"Regla: Historial de abandono previo\"),\n",
    "        (df[\"N_Sin_bolsa_de_creditos\"] >= 1, \"Sin_bolsa_de_creditos\", \"Regla: Ya tuvo sin bolsa de créditos\"),\n",
    "        (\n",
    "            (df[\"pct_aprob_acum\"] + df[\"pct_perd_acum\"] >= 1.1)\n",
    "            & (df[\"N_Periodos_adicionales\"] < 4)\n",
    "            & (df[\"pct_perd_acum\"] > 0.1),\n",
    "            \"Sin_bolsa_de_creditos\",\n",
    "            \"Regla: Exceso de créditos acumulados (>110%) con pérdida moderada\"\n",
    "        ),\n",
    "        (df[\"N_Periodos_adicionales\"] > 4, \"Pérdida_del_beneficio\", \"Regla: Más de 4 periodos adicionales\"),\n",
    "        (df[\"N_Pérdida_del_beneficio\"] >= 1, \"Pérdida_del_beneficio\", \"Regla: Ya tuvo pérdida del beneficio\"),\n",
    "        (df[\"N_Graduado\"] >= 1, \"Graduado\", \"Regla: Ya tiene graduado\"),\n",
    "        (df[\"pct_aprob_acum\"] >= 0.95, \"Graduado\", \"Regla: Aprobó 95% o más de los créditos\"),\n",
    "    ]\n",
    "\n",
    "    # Aplicar reglas\n",
    "    for mask, estado, razon in reglas:\n",
    "        resultados[mask.values] = estado\n",
    "        razon_estado[mask.values] = razon\n",
    "        clase_col = f\"prob_{estado}\"\n",
    "        if clase_col in probas_df.columns:\n",
    "            probas_df.loc[mask, clase_col] = 1.0  # Regla = probabilidad total 1\n",
    "\n",
    "    # ====== MODELO ======\n",
    "    mask_modelo = pd.isna(resultados)\n",
    "    if mask_modelo.any():\n",
    "        # Obtener predicciones y probabilidades del modelo\n",
    "        X_pred = df.loc[mask_modelo, :]\n",
    "        y_proba = pipeline.predict_proba(X_pred)\n",
    "\n",
    "        # Convertir a DataFrame\n",
    "        model_probas = pd.DataFrame(y_proba, columns=[f\"prob_{c}\" for c in le.classes_], index=X_pred.index)\n",
    "        probas_df.loc[mask_modelo, :] = model_probas\n",
    "\n",
    "        # Aplicar thresholds personalizados\n",
    "        for i, row in model_probas.iterrows():\n",
    "            clase_pred = None\n",
    "            for clase in le.classes_:\n",
    "                if clase not in thresholds:\n",
    "                    raise ValueError(f\"No se encontró threshold definido para la clase '{clase}'\")\n",
    "                if row[f\"prob_{clase}\"] >= thresholds[clase]:\n",
    "                    clase_pred = clase\n",
    "                    break\n",
    "            # Asignar la predicción: primera clase que cumple threshold o argmax\n",
    "            resultados[i] = clase_pred if clase_pred else le.classes_[np.argmax(row.values)]\n",
    "            razon_estado[i] = \"Modelo\"\n",
    "\n",
    "\n",
    "    # ====== RESULTADO FINAL ======\n",
    "    # Convertimos las filas de probas_df en dicts para devolver una estructura más limpia\n",
    "    probabilidades = [\n",
    "        {col.replace(\"prob_\", \"\"): row[col] for col in probas_df.columns}\n",
    "        for _, row in probas_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"estado\": resultados.tolist(),\n",
    "        \"probabilidades\": probabilidades,\n",
    "        \"razon_estado\": razon_estado.tolist(),\n",
    "    }\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Función auxiliar para actualizar % acumulados\n",
    "# ==========================\n",
    "def actualizar_pct(\n",
    "    pct_actual: float,\n",
    "    periodo: int,\n",
    "    distr: dict[int, list[float]]\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Actualiza el porcentaje acumulado de aprobación o pérdida \n",
    "    del periodo t → t+1 usando una distribución empírica.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pct_actual : float\n",
    "        Porcentaje acumulado actual del estudiante (entre 0 y 1).\n",
    "    periodo : int\n",
    "        Número de periodo o semestre actual del estudiante.\n",
    "    distr : dict[int, list[float]]\n",
    "        Distribución empírica de porcentajes para el nivel de formación,\n",
    "        donde las claves son los periodos y los valores son listas de porcentajes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Porcentaje acumulado actualizado, truncado a un máximo de 1.0.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Si la distribución no contiene información suficiente (lista vacía o con menos de 2 elementos),\n",
    "      el porcentaje acumulado no se modifica.\n",
    "    - Si el valor penúltimo de la lista es cero, se evita la división y se conserva el valor actual.\n",
    "    - El valor resultante se limita a 1.0 como máximo.\n",
    "    \"\"\"\n",
    "\n",
    "    lista_t1 = distr.get(periodo)\n",
    "    if not lista_t1 or len(lista_t1) < 2:\n",
    "        return pct_actual\n",
    "    penultimo = lista_t1[-2]\n",
    "    if penultimo == 0:\n",
    "        return pct_actual\n",
    "    nuevo_pct = pct_actual / penultimo\n",
    "    return min(nuevo_pct, 1.0)\n",
    "\n",
    "# ==========================\n",
    "# Simulación de trayectoria\n",
    "# ==========================\n",
    "def simular_trayectoria(\n",
    "    fila_inicial: pd.Series,\n",
    "    clf: \"sklearn.pipeline.Pipeline\",\n",
    "    le: \"sklearn.preprocessing.LabelEncoder\",\n",
    "    Distr_apr_tecnico: dict[int, list[float]],\n",
    "    Distr_tecnico: dict[int, list[float]],\n",
    "    Distr_apr_tecnologico: dict[int, list[float]],\n",
    "    Distr_tecnologico: dict[int, list[float]],\n",
    "    Distr_apr_universitario: dict[int, list[float]],\n",
    "    Distr_universitario: dict[int, list[float]],\n",
    "    thresholds: dict[str, float],\n",
    "    max_iter: int = 20\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simula la trayectoria académica de un estudiante a lo largo de varios semestres,\n",
    "    aplicando reglas de negocio y predicciones de un modelo supervisado.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fila_inicial : pandas.Series\n",
    "        Registro inicial del estudiante con sus variables académicas y de contexto.\n",
    "        Debe incluir campos como \"NIVEL_FORMACION\", \"semestre\", \"pct_aprob_acum\", etc.\n",
    "    clf : sklearn.Pipeline\n",
    "        Pipeline entrenado que contiene el preprocesamiento y el modelo predictivo.\n",
    "    le : sklearn.preprocessing.LabelEncoder\n",
    "        Codificador de etiquetas usado durante el entrenamiento del modelo.\n",
    "    Distr_apr_tecnico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos aprobados por semestre (nivel técnico).\n",
    "    Distr_tecnico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos perdidos por semestre (nivel técnico).\n",
    "    Distr_apr_tecnologico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos aprobados por semestre (nivel tecnológico).\n",
    "    Distr_tecnologico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos perdidos por semestre (nivel tecnológico).\n",
    "    Distr_apr_universitario : dict[int, list[float]]\n",
    "        Distribución empírica de créditos aprobados por semestre (nivel universitario).\n",
    "    Distr_universitario : dict[int, list[float]]\n",
    "        Distribución empírica de créditos perdidos por semestre (nivel universitario).\n",
    "    thresholds : dict[str, float]\n",
    "        Umbrales por clase usados para ajustar las predicciones del modelo.\n",
    "    max_iter : int, optional (default=20)\n",
    "        Número máximo de semestres a simular.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Trayectoria completa del estudiante, donde cada fila representa\n",
    "        un semestre simulado con sus variables actualizadas y el estado\n",
    "        resultante (\"Matriculado\", \"Abandono\", \"Graduado\", etc.).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - La simulación avanza semestre a semestre hasta alcanzar un estado absorbente\n",
    "      (por ejemplo, \"Abandono\" o \"Graduado\") o el límite de iteraciones.\n",
    "    - Se actualizan dinámicamente los contadores de estado, los porcentajes acumulados\n",
    "      y los periodos adicionales con base en reglas empíricas y las predicciones del modelo.\n",
    "    - Por defecto, todo estudiante inicia en estado \"Matriculado\" si no se especifica otro.\n",
    "    \"\"\"\n",
    "\n",
    "    fila = fila_inicial.to_dict()\n",
    "    nivel = fila[\"NIVEL_FORMACION\"]\n",
    "\n",
    "    if \"TECNICA\" in nivel.upper():\n",
    "        distr_aprob, distr_perd = Distr_apr_tecnico, Distr_tecnico\n",
    "    elif \"TECNOLOG\" in nivel.upper():\n",
    "        distr_aprob, distr_perd = Distr_apr_tecnologico, Distr_tecnologico\n",
    "    elif \"UNIVERSITARIO\" in nivel.upper():\n",
    "        distr_aprob, distr_perd = Distr_apr_universitario, Distr_universitario\n",
    "    else:\n",
    "        raise ValueError(f\"Nivel de formación no reconocido: {nivel}\")\n",
    "\n",
    "    # ====== estado inicial ======\n",
    "    #Esto garantiza que toda simulación arranque con un estado definido, y por defecto se asume que todo estudiante parte como \"Matriculado\".\n",
    "    fila[\"estado\"] = fila.get(\"estado\", \"Matriculado\")\n",
    "    \n",
    "    # 🔹 CAMBIO 1: ahora predecir_estado devuelve también probabilidades y razón\n",
    "    pred_estado = predecir_estado(pd.DataFrame([fila]), clf, le, thresholds)\n",
    "\n",
    "    # Extraer valores de la tupla devuelta (estado, dict_probs, razon)\n",
    "    fila[\"estado_next\"] = pred_estado[\"estado\"][0]\n",
    "    fila[\"razon_estado\"] = pred_estado[\"razon_estado\"][0]\n",
    "    \n",
    "    # Crear columnas de probabilidad por clase (prob_<clase>)\n",
    "    for clase, prob in pred_estado[\"probabilidades\"][0].items():\n",
    "        fila[f\"prob_{clase}\"] = prob\n",
    "    \n",
    "    trayectoria = [fila.copy()]\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        if fila[\"estado\"] in ABSORBENTES:\n",
    "            break\n",
    "        estado_actual = fila[\"estado_next\"]\n",
    "        \n",
    "        nueva = fila.copy()\n",
    "        nueva[\"estado\"] = estado_actual\n",
    "        nueva[\"semestre\"] += 1\n",
    "\n",
    "        # ====== contadores ======\n",
    "        key = f\"N_{estado_actual}\"\n",
    "        if key in nueva:\n",
    "            nueva[key] += 1\n",
    "\n",
    "        # ====== actualizar % ======\n",
    "        if estado_actual == \"Matriculado\":\n",
    "            periodo = int(nueva[\"N_Matriculado\"])\n",
    "            if (periodo + 1) not in distr_aprob or (periodo + 1) not in distr_perd:\n",
    "                break\n",
    "            nueva[\"pct_aprob_acum\"] = actualizar_pct(fila[\"pct_aprob_acum\"], periodo, distr_aprob)\n",
    "            nueva[\"pct_perd_acum\"] = actualizar_pct(fila[\"pct_perd_acum\"], periodo, distr_perd)\n",
    "\n",
    "        # ====== periodos adicionales ======\n",
    "        nueva[\"N_Periodos_adicionales\"] = max(nueva[\"semestre\"] - nueva[\"PERIODOS_BD_SNIES\"], 0)\n",
    "        nueva[\"N_Matriculas_adicionales\"] = max(nueva[\"N_Matriculado\"] - nueva[\"PERIODOS_BD_SNIES\"], 0)\n",
    "\n",
    "        # ====== periodo_key ======\n",
    "        pk = fila[\"periodo_key\"]\n",
    "        anio, sem = divmod(pk, 10)\n",
    "        nueva[\"periodo_key\"] = anio * 10 + (2 if sem == 1 else 1 + 10)\n",
    "\n",
    "        # ====== estado siguiente ======\n",
    "        # 🔹 CAMBIO 2: incluir también probabilidades y razón del estado\n",
    "        pred_estado = predecir_estado(pd.DataFrame([nueva]), clf, le, thresholds)\n",
    "        \n",
    "        nueva[\"estado_next\"] = pred_estado[\"estado\"][0]\n",
    "        nueva[\"razon_estado\"] = pred_estado[\"razon_estado\"][0]\n",
    "        \n",
    "        # Crear columnas de probabilidad por clase (prob_<clase>)\n",
    "        for clase, prob in pred_estado[\"probabilidades\"][0].items():\n",
    "            nueva[f\"prob_{clase}\"] = prob\n",
    "        \n",
    "\n",
    "        trayectoria.append(nueva.copy())\n",
    "        fila = nueva\n",
    "\n",
    "        if nueva[\"estado_next\"] in ABSORBENTES:\n",
    "            final = fila.copy()\n",
    "            final[\"estado\"] = final[\"estado_next\"]\n",
    "            key = f\"N_{final['estado_next']}\"\n",
    "            if key in final:\n",
    "                final[key] += 1\n",
    "            trayectoria.append(final.copy())\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(trayectoria)\n",
    "\n",
    "# ==========================\n",
    "# Simular todas las cédulas\n",
    "# ==========================\n",
    "def simular_todas(\n",
    "    df: pd.DataFrame,\n",
    "    clf: \"sklearn.pipeline.Pipeline\",\n",
    "    le: \"sklearn.preprocessing.LabelEncoder\",\n",
    "    Distr_apr_tecnico: dict[int, list[float]],\n",
    "    Distr_tecnico: dict[int, list[float]],\n",
    "    Distr_apr_tecnologico: dict[int, list[float]],\n",
    "    Distr_tecnologico: dict[int, list[float]],\n",
    "    Distr_apr_universitario: dict[int, list[float]],\n",
    "    Distr_universitario: dict[int, list[float]],\n",
    "    thresholds: dict[str, float],\n",
    "    max_iter: int = 20\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simula las trayectorias académicas de todos los estudiantes únicos en un DataFrame,\n",
    "    llamando internamente a `simular_trayectoria` para cada cédula.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataset filtrado con la información inicial de los estudiantes.\n",
    "        Puede contener múltiples filas por cédula, pero se tomará la última.\n",
    "    pipeline : sklearn.Pipeline\n",
    "        Pipeline entrenado que incluye preprocesamiento y modelo predictivo.\n",
    "    le : sklearn.preprocessing.LabelEncoder\n",
    "        Codificador de clases utilizado durante el entrenamiento del modelo.\n",
    "    Distr_apr_tecnico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos aprobados por semestre (nivel técnico).\n",
    "    Distr_tecnico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos perdidos por semestre (nivel técnico).\n",
    "    Distr_apr_tecnologico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos aprobados por semestre (nivel tecnológico).\n",
    "    Distr_tecnologico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos perdidos por semestre (nivel tecnológico).\n",
    "    Distr_apr_universitario : dict[int, list[float]]\n",
    "        Distribución empírica de créditos aprobados por semestre (nivel universitario).\n",
    "    Distr_universitario : dict[int, list[float]]\n",
    "        Distribución empírica de créditos perdidos por semestre (nivel universitario).\n",
    "    thresholds : dict[str, float]\n",
    "        Diccionario con los umbrales personalizados por clase.\n",
    "    max_iter : int, optional (default=20)\n",
    "        Número máximo de semestres a simular por estudiante.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame consolidado con las trayectorias de todos los estudiantes.\n",
    "        Cada cédula aparece repetida a lo largo de su secuencia temporal simulada.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - La función identifica los estudiantes únicos por el campo \"DOCUMENTO\".\n",
    "    - Se toma una única fila inicial por cédula (la más reciente).\n",
    "    - Cada estudiante se simula de manera independiente mediante `simular_trayectoria`.\n",
    "    - Los resultados se concatenan en un único DataFrame final.\n",
    "    \"\"\"\n",
    "\n",
    "    df_iniciales = df.drop_duplicates(subset=[\"DOCUMENTO\"], keep = 'last').set_index(\"DOCUMENTO\")\n",
    "\n",
    "    trayectorias = []\n",
    "\n",
    "    for cedula, fila in df_iniciales.iterrows():\n",
    "        trayectoria = simular_trayectoria(\n",
    "            fila, pipeline, le,\n",
    "            Distr_apr_tecnico, Distr_tecnico,\n",
    "            Distr_apr_tecnologico, Distr_tecnologico,\n",
    "            Distr_apr_universitario, Distr_universitario,\n",
    "            thresholds, max_iter\n",
    "        )\n",
    "        trayectoria[\"CEDULA\"] = cedula\n",
    "        trayectorias.append(trayectoria)\n",
    "\n",
    "    return pd.concat(trayectorias, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43b1c564-166a-414e-af62-1a10c98397b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simular_todas_paralelo(\n",
    "    df: pd.DataFrame,\n",
    "    pipeline: \"sklearn.pipeline.Pipeline\",\n",
    "    le: \"sklearn.preprocessing.LabelEncoder\",\n",
    "    Distr_apr_tecnico: dict[int, list[float]],\n",
    "    Distr_tecnico: dict[int, list[float]],\n",
    "    Distr_apr_tecnologico: dict[int, list[float]],\n",
    "    Distr_tecnologico: dict[int, list[float]],\n",
    "    Distr_apr_universitario: dict[int, list[float]],\n",
    "    Distr_universitario: dict[int, list[float]],\n",
    "    thresholds: dict[str, float],\n",
    "    max_iter: int = 20,\n",
    "    n_jobs: int = -1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simula trayectorias académicas para todas las cédulas en paralelo usando joblib,\n",
    "    mostrando una barra de progreso mediante tqdm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Dataset original con estudiantes (puede contener múltiples filas por cédula).\n",
    "        Se tomará una única fila por estudiante (la más reciente).\n",
    "    pipeline : sklearn.Pipeline\n",
    "        Pipeline entrenado que incluye tanto el preprocesamiento como el modelo predictivo.\n",
    "    le : sklearn.preprocessing.LabelEncoder\n",
    "        Codificador de clases usado en el entrenamiento.\n",
    "    Distr_apr_tecnico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos aprobados por semestre (nivel técnico).\n",
    "    Distr_tecnico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos perdidos por semestre (nivel técnico).\n",
    "    Distr_apr_tecnologico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos aprobados por semestre (nivel tecnológico).\n",
    "    Distr_tecnologico : dict[int, list[float]]\n",
    "        Distribución empírica de créditos perdidos por semestre (nivel tecnológico).\n",
    "    Distr_apr_universitario : dict[int, list[float]]\n",
    "        Distribución empírica de créditos aprobados por semestre (nivel universitario).\n",
    "    Distr_universitario : dict[int, list[float]]\n",
    "        Distribución empírica de créditos perdidos por semestre (nivel universitario).\n",
    "    thresholds : dict[str, float]\n",
    "        Diccionario con umbrales personalizados por clase.\n",
    "    max_iter : int, optional (default=20)\n",
    "        Número máximo de semestres a simular por estudiante.\n",
    "    n_jobs : int, optional (default=-1)\n",
    "        Número de núcleos a utilizar en paralelo (-1 = usar todos los disponibles).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        DataFrame concatenado con las trayectorias simuladas de todos los estudiantes.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - Utiliza `joblib.Parallel` y `joblib.delayed` para acelerar la simulación.\n",
    "    - Muestra una barra de progreso mediante `tqdm` durante la ejecución.\n",
    "    - Internamente llama a `simular_trayectoria` para cada cédula.\n",
    "    - Cada fila del DataFrame resultante representa un estado temporal en la trayectoria simulada.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 0. MUY IMPORTANTE: Orden cronologicamente las observaciones. \n",
    "    df = df.sort_values(by=[\"DOCUMENTO\", \"semestre\"], ascending=True) \n",
    "    # 1. MUY IMPORTANTE: Tomar la observación más reciente del individuo.\n",
    "    df_iniciales = df.drop_duplicates(subset=[\"DOCUMENTO\"], keep = 'last').set_index(\"DOCUMENTO\")\n",
    "\n",
    "    # 2. Definir función para cada cédula\n",
    "    def simular_por_cedula(fila):\n",
    "        trayectoria = simular_trayectoria(\n",
    "            fila_inicial=fila,\n",
    "            clf=pipeline,\n",
    "            le=le,\n",
    "            Distr_apr_tecnico=Distr_apr_tecnico,\n",
    "            Distr_tecnico=Distr_tecnico,\n",
    "            Distr_apr_tecnologico=Distr_apr_tecnologico,\n",
    "            Distr_tecnologico=Distr_tecnologico,\n",
    "            Distr_apr_universitario=Distr_apr_universitario,\n",
    "            Distr_universitario=Distr_universitario,\n",
    "            thresholds=thresholds,\n",
    "            max_iter=max_iter\n",
    "        )\n",
    "        trayectoria[\"CEDULA\"] = fila.name\n",
    "        return trayectoria\n",
    "\n",
    "    # 3. Paralelizar ejecución con tqdm sobre iterrows\n",
    "    trayectorias = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(simular_por_cedula)(fila)\n",
    "        for _, fila in tqdm(df_iniciales.iterrows(),\n",
    "                            total=len(df_iniciales),\n",
    "                            desc=\"Simulando trayectorias\")\n",
    "    )\n",
    "\n",
    "    # 4. Concatenar resultados\n",
    "    return pd.concat(trayectorias, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd225c0-7b7c-4f51-801f-477620fd2db4",
   "metadata": {},
   "source": [
    "**Escenarios de proyeccion para JE1 Y JE2:**\n",
    "\n",
    "0. Asumir que todos el mundo tendrá mínimo el 10% de aprobacion\n",
    "1. Asumir que todo el mundo tendrá el % de aprobación teorica\n",
    "2. Asumir que el % de aprobación se comportará como el % de aprobación teorica más un ruido gaussiano\n",
    "3. Asumir que el % de aprobación se comportará como se ha comportado en los primeros 2 semestres del pasado\n",
    "\n",
    "En este punto tenemos:\n",
    "- **a)** Dataframe con todos los jovenes (aka *df*)\n",
    "- **b)** dataframe con las observaciones de JE1 y JE2  (aka df_ultimas_observaciones_je)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36671b48-aa4b-4665-a927-ea7ec9686efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escenario 2: Asumir que todos los que tienen pct aprobado == 0 aprobaran el 10% + o - un ruido Gaussiano\n",
    "# Fijamos la semilla\n",
    "np.random.seed(42)\n",
    "\n",
    "mask = df_ultimas_observaciones_je['pct_aprob_acum'] == 0\n",
    "\n",
    "# Generamos ruido gaussiano reproducible SOLO para los ceros\n",
    "ruido = np.random.normal(loc=0.03, scale=0.01, size=mask.sum())\n",
    "\n",
    "df_ultimas_observaciones_je.loc[mask, 'pct_aprob_acum'] = 0.1 + ruido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f264b605-406d-439f-adbf-2d68c0ca514f",
   "metadata": {},
   "source": [
    "**Seleccion del DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1464204-4aaf-4c41-929c-ce27bfff7adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba0d8ec7993943ac829b084f38af442a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Selecciona df:', layout=Layout(width='60%'), options=(('JE', 'JE'), ('JU', 'JU'), ('Comp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# --- Diccionario con las tres opciones de dataframes---\n",
    "dataframes = {\n",
    "    \"JE\": df_ultimas_observaciones_je,\n",
    "    \"JU\": df_JU,\n",
    "    \"completo\": df\n",
    "}\n",
    "\n",
    "# --- Instanciar selector interactivo ---\n",
    "selector_df = widgets.Dropdown(\n",
    "    options=[(\"JE\", \"JE\"),\n",
    "             (\"JU\", \"JU\"),\n",
    "             (\"Completo JU-JE\", \"completo\"),\n",
    "            ],\n",
    "    description=\"Selecciona df:\",\n",
    "    value=\"JE\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout=widgets.Layout(width=\"60%\")\n",
    ")\n",
    "\n",
    "display(selector_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994e824-74e8-473b-a75c-88dcb5b64d0a",
   "metadata": {},
   "source": [
    "**Simular las trayectorias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05ec4d48-d263-43f9-8b2e-bc0907fcd83a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulando trayectorias: 100%|██████████████████████████████████████████████████████| 2330/2330 [12:28<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "df_trayectorias = simular_todas_paralelo(\n",
    "    df=dataframes[selector_df.value], #Posibles dataframes: df_ultimas_observaciones_je,#df,\n",
    "    pipeline=pipeline,\n",
    "    le=le,\n",
    "    Distr_apr_tecnico=Distr_apr_tecnico,\n",
    "    Distr_tecnico=Distr_tecnico,\n",
    "    Distr_apr_tecnologico=Distr_apr_tecnologico,\n",
    "    Distr_tecnologico=Distr_tecnologico,\n",
    "    Distr_apr_universitario=Distr_apr_universitario,\n",
    "    Distr_universitario=Distr_universitario,\n",
    "    thresholds=thresholds_pr,\n",
    "    max_iter=20,\n",
    "    n_jobs=-1  # Usa todos los núcleos disponibles\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f855adba",
   "metadata": {},
   "source": [
    "**Guardar resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d59dcb68-33dd-43b4-a5ac-91b2815c74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trayectorias.to_pickle(f\"trayectorias/trayectorias_{selector_df.value}_panel{version_panel}_{fecha_actual}.pkl\")\n",
    "df_trayectorias.to_excel(f\"trayectorias/trayectorias_{selector_df.value}_panel{version_panel}_{fecha_actual}.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f821e9f5-257b-4680-8b67-ae618b9bafdc",
   "metadata": {},
   "source": [
    "**Nota: 16-10-2025**\n",
    "\n",
    "Dado que el modelo está sobreestimando los abandonos para JE1 y JE2, vamos a utilizar el modelo de abandono hecho por Raúl. \n",
    "El flujo (provicional) es pasarle la base de las personas tales que:\n",
    "\n",
    "1. Su estado actual no es abandono pero su estado_next lo es.\n",
    "2. El modelo clasificó al beneficiario en abanadono directamente (no se explica por otra regla)\n",
    "\n",
    "**Nota**\n",
    "- El modelo de Raúl clasifica abandonos para los primeros 3 semestres, lo cual es ideal para este ejercicio, toda vez que las sobreestimaciones se están dando en los primeros 3 periodos.\n",
    "\n",
    "**Reflexiones**\n",
    "- Si bien el recall de Raúl es muy bueno (~~80%) la precisión es baja (~20%), lo cual implica que la sobreestimación seguirá ocurriendo (muchos falsos positivos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca11fbca-21bd-4131-90e0-f3934d1971c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trayectorias.query(\n",
    "    \"(estado_next == 'Abandono') & (razon_estado == 'Modelo') & (estado!='Abandono')\"\n",
    ")[['CEDULA', 'CONVOCATORIA']].to_excel(f\"abandono/clasificados_como_abandono_{selector_df.value}_{fecha_actual}.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
